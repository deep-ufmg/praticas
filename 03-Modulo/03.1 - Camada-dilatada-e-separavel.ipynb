{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"03.1 - Camada-dilatada-e-separavel.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"Ed03SC1Jm9Yy","colab_type":"text"},"source":["# Outras Camadas Convolucionais\n","\n","Além das camadas convolucionais padrões, algumas outras surgiram tentando melhorar alguns quesitos da convolução tradicional.\n","\n","Entre elas estão:\n","\n","- [convolução dilatada](https://arxiv.org/abs/1511.07122) (*dilated convolution*), que permite que o filtro convolucional tenha *buracos* aumentando o *receptive field* mas mantendo a resolução da imagem, e \n","- [convolução separável por canal](https://arxiv.org/abs/1704.04861) (*depthwise separable convolution*), que, de acordo com a literatura, alcança resultados similares ao da convolução padrão porém usando menos parâmetros (por isso, são mais rápidas)."]},{"cell_type":"markdown","metadata":{"id":"Gp6CwWnFnTwb","colab_type":"text"},"source":["Antes de começar, vamos instalar o MXNet. Esse pequeno bloco de código abaixo é usado somente para instalar o MXNet para CUDA 10. Execute esse bloco somente uma vez e ignore possíveis erros levantados durante a instalação.\n","\n","**ATENÇÃO: a alteração deste bloco pode implicar em problemas na execução dos blocos restantes!**"]},{"cell_type":"code","metadata":{"id":"XW-VATPAldgt","colab_type":"code","outputId":"d5b2050f-3ce0-40eb-b4a2-30648add8998","executionInfo":{"status":"ok","timestamp":1562765433312,"user_tz":180,"elapsed":20733,"user":{"displayName":"Keiller Nogueira","photoUrl":"https://lh5.googleusercontent.com/-OSbB3k7-l84/AAAAAAAAAAI/AAAAAAAAAac/z8WNFFAmye0/s64/photo.jpg","userId":"03938009311988397527"}},"colab":{"base_uri":"https://localhost:8080/","height":182}},"source":["!pip install mxnet-cu100\n","\n","# imports basicos\n","import time, os, sys, numpy as np\n","import mxnet as mx\n","from mxnet import autograd, gluon, init, nd\n","from mxnet.gluon import loss as gloss, nn, utils as gutils, data as gdata\n","\n","# Tenta encontrar GPU\n","def try_gpu():\n","    try:\n","        ctx = mx.gpu()\n","        _ = nd.zeros((1,), ctx=ctx)\n","    except mx.base.MXNetError:\n","        ctx = mx.cpu()\n","    return ctx\n","\n","ctx = try_gpu()\n","ctx"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: mxnet-cu100 in /usr/local/lib/python3.6/dist-packages (1.4.1)\n","Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu100) (0.8.4)\n","Requirement already satisfied: numpy<1.15.0,>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu100) (1.14.6)\n","Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu100) (2.21.0)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-cu100) (3.0.4)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-cu100) (2.8)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-cu100) (2019.6.16)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-cu100) (1.24.3)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["gpu(0)"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"id":"g9u0pCOtlWLu","colab_type":"code","colab":{}},"source":["## carregando dados\n","\n","# código para carregar o dataset do MNIST\n","# http://yann.lecun.com/exdb/mnist/\n","def load_data_mnist(batch_size, resize=None, root=os.path.join(\n","        '~', '.mxnet', 'datasets', 'mnist')):\n","    \"\"\"Download the MNIST dataset and then load into memory.\"\"\"\n","    root = os.path.expanduser(root)\n","    transformer = []\n","    if resize:\n","        transformer += [gdata.vision.transforms.Resize(resize)]\n","    transformer += [gdata.vision.transforms.ToTensor()]\n","    transformer = gdata.vision.transforms.Compose(transformer)\n","\n","    mnist_train = gdata.vision.MNIST(root=root, train=True)\n","    mnist_test = gdata.vision.MNIST(root=root, train=False)\n","    num_workers = 0 if sys.platform.startswith('win32') else 4\n","\n","    train_iter = gdata.DataLoader(mnist_train.transform_first(transformer),\n","                                  batch_size, shuffle=True,\n","                                  num_workers=num_workers)\n","    test_iter = gdata.DataLoader(mnist_test.transform_first(transformer),\n","                                 batch_size, shuffle=False,\n","                                 num_workers=num_workers)\n","    return train_iter, test_iter\n","\n","# código para carregar o dataset do Fashion-MNIST\n","# https://github.com/zalandoresearch/fashion-mnist\n","def load_data_fashion_mnist(batch_size, resize=None, root=os.path.join(\n","        '~', '.mxnet', 'datasets', 'fashion-mnist')):\n","    \"\"\"Download the Fashion-MNIST dataset and then load into memory.\"\"\"\n","    root = os.path.expanduser(root)\n","    transformer = []\n","    if resize:\n","        transformer += [gdata.vision.transforms.Resize(resize)]\n","    transformer += [gdata.vision.transforms.ToTensor()]\n","    transformer = gdata.vision.transforms.Compose(transformer)\n","\n","    mnist_train = gdata.vision.FashionMNIST(root=root, train=True)\n","    mnist_test = gdata.vision.FashionMNIST(root=root, train=False)\n","    num_workers = 0 if sys.platform.startswith('win32') else 4\n","\n","    train_iter = gdata.DataLoader(mnist_train.transform_first(transformer),\n","                                  batch_size, shuffle=True,\n","                                  num_workers=num_workers)\n","    test_iter = gdata.DataLoader(mnist_test.transform_first(transformer),\n","                                 batch_size, shuffle=False,\n","                                 num_workers=num_workers)\n","    return train_iter, test_iter\n","\n","# funções básicas\n","def _get_batch(batch, ctx):\n","    \"\"\"Return features and labels on ctx.\"\"\"\n","    features, labels = batch\n","    if labels.dtype != features.dtype:\n","        labels = labels.astype(features.dtype)\n","    return (gutils.split_and_load(features, ctx),\n","            gutils.split_and_load(labels, ctx), features.shape[0])\n","\n","# Função usada para calcular acurácia\n","def evaluate_accuracy(data_iter, net, loss, ctx=[mx.cpu()]):\n","    \"\"\"Evaluate accuracy of a model on the given data set.\"\"\"\n","    if isinstance(ctx, mx.Context):\n","        ctx = [ctx]\n","    acc_sum, n, l = nd.array([0]), 0, 0\n","    for batch in data_iter:\n","        features, labels, _ = _get_batch(batch, ctx)\n","        for X, y in zip(features, labels):\n","            # X, y = X.as_in_context(ctx), y.as_in_context(ctx)\n","            y = y.astype('float32')\n","            y_hat = net(X)\n","            l += loss(y_hat, y).sum()\n","            acc_sum += (y_hat.argmax(axis=1) == y).sum().copyto(mx.cpu())\n","            n += y.size\n","        acc_sum.wait_to_read()\n","    return acc_sum.asscalar() / n, l.asscalar() / n\n","  \n","# Função usada no treinamento e validação da rede\n","def train_validate(net, train_iter, test_iter, batch_size, trainer, loss, ctx,\n","                   num_epochs):\n","    print('training on', ctx)\n","    for epoch in range(num_epochs):\n","        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\n","        for X, y in train_iter:\n","            X, y = X.as_in_context(ctx), y.as_in_context(ctx)\n","            with autograd.record():\n","                y_hat = net(X)\n","                l = loss(y_hat, y).sum()\n","            l.backward()\n","            trainer.step(batch_size)\n","            y = y.astype('float32')\n","            train_l_sum += l.asscalar()\n","            train_acc_sum += (y_hat.argmax(axis=1) == y).sum().asscalar()\n","            n += y.size\n","        test_acc, test_loss = evaluate_accuracy(test_iter, net, loss, ctx)\n","        print('epoch %d, train loss %.4f, train acc %.3f, test loss %.4f, '\n","              'test acc %.3f, time %.1f sec'\n","              % (epoch + 1, train_l_sum / n, train_acc_sum / n, test_loss, \n","                 test_acc, time.time() - start))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Azv2ajIYkIjH","colab_type":"text"},"source":["## Convolucional Dilatada (*Dilated Convolution*)\n","\n","Nas camadas convolucionais dilatadas, os pesos do filtro são empregados de maneira diferente quando comparados às convoluções padrão.\n","Especificamente, os filtros dessa camada não precisam ser contíguos e podem ter lacunas (ou \"buracos\") entre seus parâmetros.\n","Essas lacunas, inseridas de acordo com a taxa de dilatação $r \\in \\mathbb{N}$, que permite um aumento do tamanho do filtro convolucional, preservando o número de parâmetros treináveis, uma vez que os buracos inseridos não são considerados no processo de convolução.\n","Portanto, esta taxa de dilatação $ r $ pode ser vista como um parâmetro responsável por definir o alinhamento final dos pesos.\n","\n","Formalmente, uma convolução dilatada 2-D recebe uma entrada em duas dimensões $ Y $, uma taxa de dilatação $ R $ e um vetor de peso 2-D $ W $ (neste caso, com tamanho $ n \\times n $) e processos eles dessa forma: \n","\n","$$ Y[k, l] = \\sum_{i=1}^{n} \\sum_{j=1}^{n} X(k + r \\times i, l + r \\times j) K(i,j) $$\n",", onde $Y$ é a saída ou *feature map*.\n","Observe as diferenças entre a dilatação e a convolução padrão apresentadas na aula anterior.\n","\n","O efeito da taxa de dilatação diferente $ r $ é apresentado na figura abaixo.\n","Como pode ser visto, taxas menores resultam em um filtro mais clusterizado (na verdade, a taxa 1 gera um filtro idêntico à convolução padrão) enquanto as taxas maiores fazem uma expansão do filtro, produzindo um kernel maior com vários buracos.\n","Como todo esse processo de dilatação do filtro é independente dos dados de entrada, alterar a taxa de dilatação não afeta a resolução do resultado, ou seja, em uma convolução dilatada, independente da taxa, a entrada e a saída têm a mesma resolução (considerando, claro, o efeito do *padding* e do *stride*).\n","\n","<p align=\"center\">\n","  <img width=\"500\" src=\"https://drive.google.com/uc?export=view&id=1HixSXbx3HKWUrcCqJ8d-IF-RTykoT2Pz\">\n","</p>\n","\n","<p align=\"center\">\n","  <img src=\"https://cdn-images-1.medium.com/max/800/0*oX5IPr7TlVM2NpEU.gif\">\n","  <img src=\"https://cdn-images-1.medium.com/max/800/0*3cTXIemm0k3Sbask.gif\">\n","</p>\n","\n","Ao ampliar o filtro (com essas lacunas), a rede expande seu campo receptivo (já que os pesos serão organizados em uma forma mais esparsa), mas preserva a resolução e nenhuma redução de resolução nos dados é executada.\n","Portanto, esse processo tem várias vantagens, como:\n","(i) suporta a expansão do campo receptivo sem aumentar o número de parâmetros treináveis por camada, o que reduz a carga computacional, e\n","(ii) preserva a resolução do mapa de características, o que pode ajudar a rede a extrair informações ainda mais úteis dos dados, principalmente de pequenos objetos.\n","\n","### Campo Receptivo (*Receptive Field*)\n","\n","O campo receptivo é definido como a região no espaço de entrada que tem influência sobre a saída atual da rede convolucional.\n","\n","<p align=\"center\">\n","  <img src=\"https://miro.medium.com/max/1000/1*mModSYik9cD9XJNemdTraw.png\">\n","</p>\n","\n","### Implementação\n","\n","No MXNet, a [camada convolução padrão](https://beta.mxnet.io/api/gluon/_autogen/mxnet.gluon.nn.Conv2D.html) tem suporte para dilatação dos filtros de acordo com o parâmetro *dilation*.\n"]},{"cell_type":"code","metadata":{"id":"e5ad4OFLu9NM","colab_type":"code","colab":{}},"source":["class LeNet(nn.Block):\n","    def __init__(self, classes=10, **kwargs):\n","        super(LeNet, self).__init__(**kwargs)\n","        with self.name_scope():\n","            self.conv1 = nn.Conv2D(6, kernel_size=5, strides=1, padding=0, activation='tanh')    # entrada: (b, 1, 32, 32) e saida: (b, 6, 28, 28)\n","            self.avgpool1 = nn.AvgPool2D(pool_size=2, strides=2)                                 # entrada: (b, 6, 28, 28) e saida: (b, 6, 14, 14)\n","            self.conv2 = nn.Conv2D(16, kernel_size=5, strides=1, padding=0, dilation=2, activation='tanh')   # entrada: (b, 6, 14, 14) e saida: (b, 16, 10, 10)\n","            # self.avgpool2 = nn.AvgPool2D(pool_size=2, strides=2)                                 # entrada: (b, 16, 10, 10) e saida: (b, 16, 5, 5)\n","            # self.conv3 = nn.Conv2D(120, kernel_size=5, strides=1, padding=0, activation='tanh')  # entrada: (b, 16, 5, 5) e saida: (b, 120, 1, 1)\n","            self.flatten = nn.Flatten()  # lineariza formando um vetor                           # entrada: (b, 120, 14, 14) e saida: (b, 120*20*20) = (b, 48000)\n","            self.fc1 = nn.Dense(84, activation=\"tanh\")                                           # entrada: (b, 48000) e saida: (b, 84)\n","            self.fc2 = nn.Dense(classes)                                                         # entrada: (b, 84) e saida: (b, 10)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.avgpool1(x)\n","        x = self.conv2(x)\n","        # print(x.shape)\n","        # x = self.avgpool2(x)\n","        # x = self.conv3(x)\n","        x = self.flatten(x)\n","        x = self.fc1(x)\n","        x = self.fc2(x)\n","\n","        return x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pd6J4s1UeCfZ","colab_type":"code","outputId":"49d0680f-443d-462f-e91f-eec81c08afc5","executionInfo":{"status":"ok","timestamp":1562716456185,"user_tz":180,"elapsed":94967,"user":{"displayName":"Keiller Nogueira","photoUrl":"https://lh5.googleusercontent.com/-OSbB3k7-l84/AAAAAAAAAAI/AAAAAAAAAac/z8WNFFAmye0/s64/photo.jpg","userId":"03938009311988397527"}},"colab":{"base_uri":"https://localhost:8080/","height":219}},"source":["# parâmetros: número de epochs, learning rate (ou taxa de aprendizado), \n","# tamanho do batch, e lambda do weight decay\n","num_epochs, lr, batch_size, wd_lambda = 10, 0.1, 128, 0.000001\n","\n","# rede baseada na LeNet-5 \n","net = LeNet()\n","net.initialize(init.Normal(sigma=0.01), ctx=ctx)\n","\n","# função de custo (ou loss)\n","loss = gloss.SoftmaxCrossEntropyLoss()\n","\n","# carregamento do dado: mnist\n","train_iter, test_iter = load_data_fashion_mnist(batch_size, resize=32)\n","\n","# trainer do gluon\n","trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': lr, 'wd': wd_lambda, 'momentum': 0.9})\n","\n","# treinamento e validação via MXNet\n","train_validate(net, train_iter, test_iter, batch_size, trainer, loss, \n","               ctx, num_epochs)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["training on gpu(0)\n","epoch 1, train loss 0.9418, train acc 0.635, test loss 0.4894, test acc 0.819, time 9.7 sec\n","epoch 2, train loss 0.4286, train acc 0.842, test loss 0.4128, test acc 0.851, time 9.4 sec\n","epoch 3, train loss 0.3843, train acc 0.861, test loss 0.3758, test acc 0.864, time 9.0 sec\n","epoch 4, train loss 0.3550, train acc 0.869, test loss 0.3709, test acc 0.862, time 9.1 sec\n","epoch 5, train loss 0.3444, train acc 0.873, test loss 0.3685, test acc 0.869, time 9.6 sec\n","epoch 6, train loss 0.3218, train acc 0.881, test loss 0.3679, test acc 0.870, time 9.0 sec\n","epoch 7, train loss 0.3169, train acc 0.883, test loss 0.3479, test acc 0.869, time 9.3 sec\n","epoch 8, train loss 0.2986, train acc 0.891, test loss 0.3165, test acc 0.887, time 9.4 sec\n","epoch 9, train loss 0.2872, train acc 0.893, test loss 0.3313, test acc 0.884, time 9.4 sec\n","epoch 10, train loss 0.2804, train acc 0.895, test loss 0.3290, test acc 0.882, time 9.4 sec\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Wwis9qbaGO6K","colab_type":"text"},"source":["Para efeito de **comparação**, recriamos a rede sem as duas camadas convolucionais (removidas na arquitetura anterior) e sem camadas dilatadas. Dessa forma, podemos observar o ganho das convoluções dilatadas."]},{"cell_type":"code","metadata":{"id":"QKan8q9eE27X","colab_type":"code","colab":{}},"source":["class LeNet(nn.Block):\n","    def __init__(self, classes=10, **kwargs):\n","        super(LeNet, self).__init__(**kwargs)\n","        with self.name_scope():\n","            self.conv1 = nn.Conv2D(6, kernel_size=5, strides=1, padding=0, activation='tanh')    # entrada: (b, 1, 32, 32) e saida: (b, 6, 28, 28)\n","            self.avgpool1 = nn.AvgPool2D(pool_size=2, strides=2)                                 # entrada: (b, 6, 28, 28) e saida: (b, 6, 14, 14)\n","            self.conv2 = nn.Conv2D(16, kernel_size=5, strides=1, padding=0, activation='tanh')   # entrada: (b, 6, 14, 14) e saida: (b, 16, 10, 10)\n","            # self.avgpool2 = nn.AvgPool2D(pool_size=2, strides=2)                                 # entrada: (b, 16, 10, 10) e saida: (b, 16, 5, 5)\n","            # self.conv3 = nn.Conv2D(120, kernel_size=5, strides=1, padding=0, activation='tanh')  # entrada: (b, 16, 5, 5) e saida: (b, 120, 1, 1)\n","            self.flatten = nn.Flatten()  # lineariza formando um vetor                           # entrada: (b, 120, 14, 14) e saida: (b, 120*20*20) = (b, 48000)\n","            self.fc1 = nn.Dense(84, activation=\"tanh\")                                           # entrada: (b, 48000) e saida: (b, 84)\n","            self.fc2 = nn.Dense(classes)                                                         # entrada: (b, 84) e saida: (b, 10)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.avgpool1(x)\n","        x = self.conv2(x)\n","        # print(x.shape)\n","        # x = self.avgpool2(x)\n","        # x = self.conv3(x)\n","        x = self.flatten(x)\n","        x = self.fc1(x)\n","        x = self.fc2(x)\n","\n","        return x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ahEsboG3E5TZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":313},"outputId":"d06aefc1-b758-40d3-b579-3a07e01a2a27","executionInfo":{"status":"ok","timestamp":1562765639114,"user_tz":180,"elapsed":190451,"user":{"displayName":"Keiller Nogueira","photoUrl":"https://lh5.googleusercontent.com/-OSbB3k7-l84/AAAAAAAAAAI/AAAAAAAAAac/z8WNFFAmye0/s64/photo.jpg","userId":"03938009311988397527"}}},"source":["# parâmetros: número de epochs, learning rate (ou taxa de aprendizado), \n","# tamanho do batch, e lambda do weight decay\n","num_epochs, lr, batch_size, wd_lambda = 10, 0.1, 128, 0.000001\n","\n","# rede baseada na LeNet-5 \n","net = LeNet()\n","net.initialize(init.Normal(sigma=0.01), ctx=ctx)\n","\n","# função de custo (ou loss)\n","loss = gloss.SoftmaxCrossEntropyLoss()\n","\n","# carregamento do dado: mnist\n","train_iter, test_iter = load_data_fashion_mnist(batch_size, resize=32)\n","\n","# trainer do gluon\n","trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': lr, 'wd': wd_lambda, 'momentum': 0.9})\n","\n","# treinamento e validação via MXNet\n","train_validate(net, train_iter, test_iter, batch_size, trainer, loss, \n","               ctx, num_epochs)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Downloading /root/.mxnet/datasets/fashion-mnist/train-images-idx3-ubyte.gz from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/train-images-idx3-ubyte.gz...\n","Downloading /root/.mxnet/datasets/fashion-mnist/train-labels-idx1-ubyte.gz from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/train-labels-idx1-ubyte.gz...\n","Downloading /root/.mxnet/datasets/fashion-mnist/t10k-images-idx3-ubyte.gz from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/t10k-images-idx3-ubyte.gz...\n","Downloading /root/.mxnet/datasets/fashion-mnist/t10k-labels-idx1-ubyte.gz from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/t10k-labels-idx1-ubyte.gz...\n","training on gpu(0)\n","epoch 1, train loss 0.8227, train acc 0.687, test loss 0.4786, test acc 0.827, time 18.4 sec\n","epoch 2, train loss 0.4624, train acc 0.831, test loss 0.4566, test acc 0.836, time 18.2 sec\n","epoch 3, train loss 0.4282, train acc 0.846, test loss 0.4249, test acc 0.846, time 19.2 sec\n","epoch 4, train loss 0.4117, train acc 0.850, test loss 0.3881, test acc 0.860, time 12.7 sec\n","epoch 5, train loss 0.3879, train acc 0.862, test loss 0.3999, test acc 0.854, time 12.0 sec\n","epoch 6, train loss 0.3699, train acc 0.866, test loss 0.3547, test acc 0.869, time 11.8 sec\n","epoch 7, train loss 0.3642, train acc 0.868, test loss 0.3504, test acc 0.876, time 17.8 sec\n","epoch 8, train loss 0.3507, train acc 0.872, test loss 0.3876, test acc 0.866, time 17.7 sec\n","epoch 9, train loss 0.3413, train acc 0.875, test loss 0.3430, test acc 0.873, time 25.5 sec\n","epoch 10, train loss 0.3317, train acc 0.880, test loss 0.3769, test acc 0.861, time 29.6 sec\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"RRXaLpXuROOJ","colab_type":"text"},"source":["## Convolução Separável por Canal (*Depthwise Separable Convolution*)\n","\n","Após o resurgimento das redes neurais, a cada nova arquitetura proposta, mais e mais camadas e parâmetros foram sendo usados. Por exemplo, a primeira arquitetura dessa nova onda, a [AlexNet](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=2ahUKEwi6usf1sqXjAhWFGLkGHXhPBC4QFjAAegQIAhAC&url=https%3A%2F%2Fpapers.nips.cc%2Fpaper%2F4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf&usg=AOvVaw2hqjjvSjIpuuCLLdojAmS5), tem **61.100.840** de parâmetros.\n","\n","Claramente, pelo tamanho de parâmetros, arquitetura como essas não são passíveis de serem treinadas em dispositivos com menos memória, como sistema embarcados, celulares, tablets, etc.\n","Por isso, uma linha de pesquisa procura otimizar o uso dos parâmetros em rede neurais.\n","Para esse fim, essa linha de pesquisa propôs uma nova camada, chamada Convolução Separável por Canal (*Depthwise Separable Convolution*), que é capaz de reproduzir arquiteturas convolucionais, obtendo resultados similar, porém com menos parâmetros.\n","\n","A ideia por trás dessa camada é representada abaixo. Ao invés de ter uma única camada de convolução que processará toda a entrada (ou seja, terá parâmetros para todos os canais de entrada), essa convolução é dividida em duas partes. Na primeira parte, cada canal é processado separadamente por um filtro específico. Formalmente, suponha que a entrada tenha $c_i$ canais.\n","Nesse caso, a primeira parte de convolução terá  $c_i$ filtros de tamanho $k\\times k$, onde cada um desses filtros processará somente um canal da entrada, gerando $c_i$ *feature maps* de saída. Na segunda parte, esses *feature maps* serão processados por uma convolução $1\\times 1$, que gerará a saída final esperada. Suponha que queiramos que essa camada gere $c_o$ canais de saída. Essa segunda parte terá $c_o$ filtros de $1\\times 1$ que processarão os *feature maps* gerados na primeira parte, gerando a saída final com $c_o$ canais.\n","\n","<p align=\"center\">\n","  <img src=\"https://cdn-images-1.medium.com/max/800/1*Voah8cvrs7gnTDf6acRvDw.png\">\n","</p>\n","\n","Vamos examinar a diferença entre a convolução padrão e a convolução separável por canal em termos de número de parâmetros. Suponha que:\n","\n","- n, seja a dimensão espacial (largura e altura), da entrada,\n","- k, seja largura e altura do filtro,\n","- c_i, seja o número de canais de entrada, e\n","- c_o, o número de canais de saída.\n","\n","Uma convolução regular tem k * k * c_i * c_o parâmetros, porque, para cada canal de saída, há um filtro $k\\times k$ para cada canal de entrada.\n","Em contrapartida, as convoluções separáveis por canal tem k * k * c_i parâmetros na primeira parte e, em seguida,  1 * 1 * c_i * c_o parâmetros para a segunda parte. Deve ser óbvio que, para um c_o não trivial, a soma desses dois é significativamente menor que k * k * c_i * c_o.\n","\n","Agora, vamos comparar o custo computacional. Para uma convolução regular, realizamos K * K * c_i operações em cada posição da entrada (para calcular a convolução 2D em 3 dimensões). Para toda a entrada, o número de cálculos é, portanto, k * k * c_i * n * n e tomando todos os canais de saída, obtemos k * k * c_i * n * n * c_o.\n","Para convoluções separáveis em profundidade, precisamos de operações k * k * c_i * n * n para a parte de profundidade; então precisamos de n * n * c_i * c_o operações para a parte de mistura. \n","\n","Vamos usar alguns números reais para sentir a diferença.\n","Assumiremos \n","\n","- n = 128, \n","- k = 3, \n","- c_i = 3, \n","- c_o = 16. \n","\n","Para convolução regular:\n","\n","     Parâmetros: 3 * 3 * 3 * 16 = 432\n","     Custo de computação: 3 * 3 * 3 * 128 * 128 * 16 = ~ 7e6\n","\n","Para a convolução separável em profundidade:\n","\n","     Parâmetros: 3 * 3 * 3 + 3 * 16 = 75\n","     Custo de computação: 3 * 3 * 3 * 128 * 128 + 128 * 128 * 3 * 16 = ~ 1.2e6"]},{"cell_type":"markdown","metadata":{"id":"SDlcHJgz1UNW","colab_type":"text"},"source":["Frameworks modernos implementam esse tipo de camada de forma diferente. No MXNet, nosso caso de estudo, a primeira parte dessa convolução é feita quando se coloca o [número de grupos da camada convolucional igual ao número de canais de entrada](https://github.com/apache/incubator-mxnet/issues/10142#issuecomment-373895855). Esse [parâmetro](https://beta.mxnet.io/api/gluon/_autogen/mxnet.gluon.nn.Conv2D.html) é usado para definir o agrupamento entre canais de entrada e filtros/neurônios. Logo, quando se tem um número de canais de entrada igual ao número de filtros, e também igual ao número de grupos. Dessa forma, cada filtro processará somente um canal.\n","\n","Já a segunda parte dessa convolução é feita naturalmente, usando o *kernel*=1.\n","\n","Abaixo, implementamos a LeNet-5 usando essa convolução.\n","\n","<p align=\"center\">\n","  <img width=700 src=\"https://engmrk.com/wp-content/uploads/2018/09/LeNEt_Summary_Table.jpg\">\n","</p>\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"W-Psc19V1Lqg","colab":{}},"source":["class LeNet(nn.Block):\n","    def __init__(self, classes=10, **kwargs):\n","        super(LeNet, self).__init__(**kwargs)\n","        with self.name_scope():\n","            self.conv1_1 = nn.Conv2D(1, kernel_size=5, strides=1, padding=0, groups=1)  # entrada: (b, 1, 32, 32) e saida: (b, 1, 28, 28)\n","            self.conv1_2 = nn.Conv2D(6, kernel_size=1, strides=1, padding=0, activation='tanh')            # entrada: (b, 1, 28, 28) e saida: (b, 6, 28, 28)\n","            self.avgpool1 = nn.AvgPool2D(pool_size=2, strides=2)                                           # entrada: (b, 6, 28, 28) e saida: (b, 6, 14, 14)\n","            \n","            self.conv2_1 = nn.Conv2D(6, kernel_size=5, strides=1, padding=0, groups=6)  # entrada: (b, 6, 14, 14) e saida: (b, 6, 10, 10)\n","            self.conv2_2 = nn.Conv2D(16, kernel_size=1, strides=1, padding=0, activation='tanh')           # entrada: (b, 6, 10, 10) e saida: (b, 16, 10, 10)\n","            self.avgpool2 = nn.AvgPool2D(pool_size=2, strides=2)                                           # entrada: (b, 16, 10, 10) e saida: (b, 16, 5, 5)\n","            \n","            self.conv3_1 = nn.Conv2D(16, kernel_size=5, strides=1, padding=0, groups=16) # entrada: (b, 16, 5, 5) e saida: (b, 16, 1, 1)\n","            self.conv3_2 = nn.Conv2D(120, kernel_size=1, strides=1, padding=0, activation='tanh')           # entrada: (b, 16, 1, 1) e saida: (b, 120, 1, 1)\n","\n","            self.flatten = nn.Flatten()  # lineariza formando um vetor                           # entrada: (b, 120, 1, 1) e saida: (b, 120*1*1) = (b, 120)\n","            self.fc1 = nn.Dense(84, activation=\"tanh\")                                           # entrada: (b, 120) e saida: (b, 84)\n","            self.fc2 = nn.Dense(classes)                                                         # entrada: (b, 84) e saida: (b, 10)\n","\n","    def forward(self, x):\n","        # print('x', x.shape)\n","        x = self.conv1_1(x)\n","        # print('conv1_1', x.shape)\n","        x = self.conv1_2(x)\n","        # print('conv1_2', x.shape)\n","        x = self.avgpool1(x)\n","        x = self.conv2_1(x)\n","        # print('conv2_1', x.shape)\n","        x = self.conv2_2(x)\n","        # print('conv2_2', x.shape)\n","        x = self.avgpool2(x)\n","        x = self.conv3_1(x)\n","        # print('conv3_1', x.shape)\n","        x = self.conv3_2(x)\n","        # print('conv3_2', x.shape)\n","        x = self.flatten(x)\n","        x = self.fc1(x)\n","        x = self.fc2(x)\n","\n","        return x"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rJcNvFRHNwfe","colab_type":"text"},"source":["## Se antes, essa arquitetura tinha 61.470 parâmetros, agora ela tem somente 13.517 (4,5 vezes menos)‬."]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"de9523f4-de0f-4c09-83bf-cfcb10ca7df7","executionInfo":{"status":"ok","timestamp":1562716644693,"user_tz":180,"elapsed":107179,"user":{"displayName":"Keiller Nogueira","photoUrl":"https://lh5.googleusercontent.com/-OSbB3k7-l84/AAAAAAAAAAI/AAAAAAAAAac/z8WNFFAmye0/s64/photo.jpg","userId":"03938009311988397527"}},"id":"fkRcFCBy1Lq3","colab":{"base_uri":"https://localhost:8080/","height":219}},"source":["# parâmetros: número de epochs, learning rate (ou taxa de aprendizado), \n","# tamanho do batch, e lambda do weight decay\n","num_epochs, lr, batch_size, wd_lambda = 10, 0.01, 128, 0.000001\n","\n","# rede baseada na LeNet-5 \n","net = LeNet()\n","net.initialize(init.Normal(sigma=0.01), ctx=ctx)\n","\n","# função de custo (ou loss)\n","loss = gloss.SoftmaxCrossEntropyLoss()\n","\n","# carregamento do dado: mnist\n","train_iter, test_iter = load_data_fashion_mnist(batch_size, resize=32)\n","\n","# trainer do gluon\n","trainer = gluon.Trainer(net.collect_params(), 'adam', {'learning_rate': lr, 'wd': wd_lambda})\n","\n","# treinamento e validação via MXNet\n","train_validate(net, train_iter, test_iter, batch_size, trainer, loss, \n","               ctx, num_epochs)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["training on gpu(0)\n","epoch 1, train loss 1.0537, train acc 0.587, test loss 0.6860, test acc 0.740, time 10.5 sec\n","epoch 2, train loss 0.6245, train acc 0.765, test loss 0.5870, test acc 0.789, time 10.1 sec\n","epoch 3, train loss 0.5336, train acc 0.803, test loss 0.5074, test acc 0.815, time 10.7 sec\n","epoch 4, train loss 0.4946, train acc 0.819, test loss 0.4978, test acc 0.812, time 10.5 sec\n","epoch 5, train loss 0.4833, train acc 0.823, test loss 0.4777, test acc 0.825, time 10.6 sec\n","epoch 6, train loss 0.4680, train acc 0.830, test loss 0.4781, test acc 0.820, time 10.4 sec\n","epoch 7, train loss 0.4522, train acc 0.836, test loss 0.4880, test acc 0.833, time 10.5 sec\n","epoch 8, train loss 0.4490, train acc 0.837, test loss 0.4469, test acc 0.837, time 10.5 sec\n","epoch 9, train loss 0.4443, train acc 0.839, test loss 0.4544, test acc 0.833, time 10.5 sec\n","epoch 10, train loss 0.4319, train acc 0.843, test loss 0.4293, test acc 0.845, time 10.6 sec\n"],"name":"stdout"}]}]}
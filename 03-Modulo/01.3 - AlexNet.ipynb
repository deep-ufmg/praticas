{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"01.3 - AlexNet.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"Ed03SC1Jm9Yy","colab_type":"text"},"source":["# Prática: Redes Neurais Convolucionais\n","\n","Vamos agora implementar a rede [AlexNet](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf), uma das redes que trouxeram todo esse interesse para a área de *deep learning*.\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"Dx_n6rukq1RG","colab_type":"code","outputId":"81713566-ddbe-44b4-df55-c40f1a86e615","executionInfo":{"status":"ok","timestamp":1562192980789,"user_tz":180,"elapsed":20023,"user":{"displayName":"Keiller Nogueira","photoUrl":"https://lh5.googleusercontent.com/-OSbB3k7-l84/AAAAAAAAAAI/AAAAAAAAAac/z8WNFFAmye0/s64/photo.jpg","userId":"03938009311988397527"}},"colab":{"base_uri":"https://localhost:8080/","height":164}},"source":["!pip install mxnet-cu100\n","\n","# imports basicos\n","import time, os, sys, numpy as np\n","import mxnet as mx\n","from mxnet import autograd, gluon, init, nd\n","from mxnet.gluon import loss as gloss, nn, utils as gutils, data as gdata\n","\n","# Tenta encontrar GPU\n","def try_gpu():\n","    try:\n","        ctx = mx.gpu()\n","        _ = nd.zeros((1,), ctx=ctx)\n","    except mx.base.MXNetError:\n","        ctx = mx.cpu()\n","    return ctx\n","\n","ctx = try_gpu()\n","ctx\n","\n","## carregando dados\n","\n","# código para carregar o dataset do MNIST\n","# http://yann.lecun.com/exdb/mnist/\n","def load_data_mnist(batch_size, resize=None, root=os.path.join(\n","        '~', '.mxnet', 'datasets', 'mnist')):\n","    \"\"\"Download the MNIST dataset and then load into memory.\"\"\"\n","    root = os.path.expanduser(root)\n","    transformer = []\n","    if resize:\n","        transformer += [gdata.vision.transforms.Resize(resize)]\n","    transformer += [gdata.vision.transforms.ToTensor()]\n","    transformer = gdata.vision.transforms.Compose(transformer)\n","\n","    mnist_train = gdata.vision.MNIST(root=root, train=True)\n","    mnist_test = gdata.vision.MNIST(root=root, train=False)\n","    num_workers = 0 if sys.platform.startswith('win32') else 4\n","\n","    train_iter = gdata.DataLoader(mnist_train.transform_first(transformer),\n","                                  batch_size, shuffle=True,\n","                                  num_workers=num_workers)\n","    test_iter = gdata.DataLoader(mnist_test.transform_first(transformer),\n","                                 batch_size, shuffle=False,\n","                                 num_workers=num_workers)\n","    return train_iter, test_iter\n","\n","# código para carregar o dataset do CIFAR 10\n","# https://www.cs.toronto.edu/~kriz/cifar.html\n","def load_data_cifar10(batch_size, resize=None, root=os.path.join(\n","        '~', '.mxnet', 'datasets', 'cifar10')):\n","    \"\"\"Download the MNIST dataset and then load into memory.\"\"\"\n","    root = os.path.expanduser(root)\n","    transformer = []\n","    if resize:\n","        transformer += [gdata.vision.transforms.Resize(resize)]\n","    transformer += [gdata.vision.transforms.ToTensor()]\n","    transformer = gdata.vision.transforms.Compose(transformer)\n","\n","    mnist_train = gdata.vision.CIFAR10(root=root, train=True)\n","    mnist_test = gdata.vision.CIFAR10(root=root, train=False)\n","    num_workers = 0 if sys.platform.startswith('win32') else 4\n","\n","    train_iter = gdata.DataLoader(mnist_train.transform_first(transformer),\n","                                  batch_size, shuffle=True,\n","                                  num_workers=num_workers)\n","    test_iter = gdata.DataLoader(mnist_test.transform_first(transformer),\n","                                 batch_size, shuffle=False,\n","                                 num_workers=num_workers)\n","    return train_iter, test_iter\n","  \n","# funções básicas\n","def _get_batch(batch, ctx):\n","    \"\"\"Return features and labels on ctx.\"\"\"\n","    features, labels = batch\n","    if labels.dtype != features.dtype:\n","        labels = labels.astype(features.dtype)\n","    return (gutils.split_and_load(features, ctx),\n","            gutils.split_and_load(labels, ctx), features.shape[0])\n","\n","# Função usada para calcular acurácia\n","def evaluate_accuracy(data_iter, net, loss, ctx=[mx.cpu()]):\n","    \"\"\"Evaluate accuracy of a model on the given data set.\"\"\"\n","    if isinstance(ctx, mx.Context):\n","        ctx = [ctx]\n","    acc_sum, n, l = nd.array([0]), 0, 0\n","    for batch in data_iter:\n","        features, labels, _ = _get_batch(batch, ctx)\n","        for X, y in zip(features, labels):\n","            # X, y = X.as_in_context(ctx), y.as_in_context(ctx)\n","            y = y.astype('float32')\n","            y_hat = net(X)\n","            l += loss(y_hat, y).sum()\n","            acc_sum += (y_hat.argmax(axis=1) == y).sum().copyto(mx.cpu())\n","            n += y.size\n","        acc_sum.wait_to_read()\n","    return acc_sum.asscalar() / n, l.asscalar() / n\n","  \n","# Função usada no treinamento e validação da rede\n","def train_validate(net, train_iter, test_iter, batch_size, trainer, loss, ctx,\n","                   num_epochs):\n","    print('training on', ctx)\n","    for epoch in range(num_epochs):\n","        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\n","        for X, y in train_iter:\n","            X, y = X.as_in_context(ctx), y.as_in_context(ctx)\n","            with autograd.record():\n","                y_hat = net(X)\n","                l = loss(y_hat, y).sum()\n","            l.backward()\n","            trainer.step(batch_size)\n","            y = y.astype('float32')\n","            train_l_sum += l.asscalar()\n","            train_acc_sum += (y_hat.argmax(axis=1) == y).sum().asscalar()\n","            n += y.size\n","        test_acc, test_loss = evaluate_accuracy(test_iter, net, loss, ctx)\n","        print('epoch %d, train loss %.4f, train acc %.3f, test loss %.4f, '\n","              'test acc %.3f, time %.1f sec'\n","              % (epoch + 1, train_l_sum / n, train_acc_sum / n, test_loss, \n","                 test_acc, time.time() - start))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: mxnet-cu100 in /usr/local/lib/python3.6/dist-packages (1.4.1)\n","Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu100) (2.21.0)\n","Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu100) (0.8.4)\n","Requirement already satisfied: numpy<1.15.0,>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu100) (1.14.6)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-cu100) (2.8)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-cu100) (1.24.3)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-cu100) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-cu100) (2019.6.16)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"mA3x5yGAiRDG","colab_type":"text"},"source":["## AlexNet\n","\n","Agora já temos todo o conhecimento necessário para implementar nossa primeira arquitetura moderna.\n","Vamos implementar a [AlexNet](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf), uma das arquiteturas mais famosas dessa nova onda de rede neurais.\n","\n","<p align=\"center\">\n","  <img width=700 src=\"https://www.researchgate.net/profile/Jaime_Gallego2/publication/318168077/figure/fig1/AS:578190894927872@1514862859810/AlexNet-CNN-architecture-layers.png\">\n","</p>\n","\n","<p align=\"center\">\n","  <img width=700 src=\"https://engmrk.com/wp-content/uploads/2018/10/AlexNet_Summary_Table.jpg\">\n","</p>\n"]},{"cell_type":"code","metadata":{"id":"ghmYljpKjIQp","colab_type":"code","outputId":"41092d7b-d454-46c5-b5ab-f8aed8fdd5a2","executionInfo":{"status":"ok","timestamp":1562197490995,"user_tz":180,"elapsed":2206097,"user":{"displayName":"Keiller Nogueira","photoUrl":"https://lh5.googleusercontent.com/-OSbB3k7-l84/AAAAAAAAAAI/AAAAAAAAAac/z8WNFFAmye0/s64/photo.jpg","userId":"03938009311988397527"}},"colab":{"base_uri":"https://localhost:8080/","height":403}},"source":["num_epochs, lr, batch_size, wd_lambda = 20, 0.001, 100, 0.0001\n","    \n","# Implementa sua rede neural aqui\n","# Voce pode implementar criando uma variavel net e adicionando as camadas net = nn.Sequential()\n","# Ou pode criar como uma classe\n","net.initialize(init.Normal(sigma=0.01), ctx=ctx)\n","\n","# função de custo (ou loss)\n","loss = gloss.SoftmaxCrossEntropyLoss()\n","\n","# carregamento do dado: fashion mnist\n","train_iter, test_iter = load_data_cifar10(batch_size, resize=227)\n","\n","# trainer do gluon\n","trainer = gluon.Trainer(net.collect_params(), 'adam', {'learning_rate': lr, 'wd': wd_lambda})\n","\n","# treinamento e validação via MXNet\n","train_validate(net, train_iter, test_iter, batch_size, trainer, loss, \n","               ctx, num_epochs)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["training on gpu(0)\n","epoch 1, train loss 2.0776, train acc 0.216, test loss 1.8543, test acc 0.316, time 112.6 sec\n","epoch 2, train loss 1.8232, train acc 0.327, test loss 1.7190, test acc 0.372, time 109.5 sec\n","epoch 3, train loss 1.7367, train acc 0.362, test loss 1.6373, test acc 0.403, time 110.0 sec\n","epoch 4, train loss 1.6363, train acc 0.398, test loss 1.5274, test acc 0.441, time 109.2 sec\n","epoch 5, train loss 1.5410, train acc 0.437, test loss 1.4531, test acc 0.470, time 110.5 sec\n","epoch 6, train loss 1.4811, train acc 0.460, test loss 1.3915, test acc 0.492, time 110.3 sec\n","epoch 7, train loss 1.4316, train acc 0.482, test loss 1.3806, test acc 0.495, time 110.1 sec\n","epoch 8, train loss 1.3982, train acc 0.492, test loss 1.3537, test acc 0.513, time 110.6 sec\n","epoch 9, train loss 1.3610, train acc 0.506, test loss 1.3530, test acc 0.513, time 110.4 sec\n","epoch 10, train loss 1.3409, train acc 0.515, test loss 1.3089, test acc 0.527, time 110.5 sec\n","epoch 11, train loss 1.3094, train acc 0.526, test loss 1.3133, test acc 0.530, time 110.0 sec\n","epoch 12, train loss 1.2894, train acc 0.535, test loss 1.2589, test acc 0.544, time 109.9 sec\n","epoch 13, train loss 1.2623, train acc 0.547, test loss 1.2554, test acc 0.553, time 110.0 sec\n","epoch 14, train loss 1.2413, train acc 0.553, test loss 1.2118, test acc 0.562, time 109.6 sec\n","epoch 15, train loss 1.2218, train acc 0.561, test loss 1.2195, test acc 0.559, time 109.7 sec\n","epoch 16, train loss 1.1937, train acc 0.571, test loss 1.2032, test acc 0.569, time 110.0 sec\n","epoch 17, train loss 1.1677, train acc 0.579, test loss 1.1939, test acc 0.567, time 110.2 sec\n","epoch 18, train loss 1.1489, train acc 0.588, test loss 1.1515, test acc 0.584, time 110.1 sec\n","epoch 19, train loss 1.1279, train acc 0.594, test loss 1.1657, test acc 0.579, time 109.8 sec\n","epoch 20, train loss 1.1110, train acc 0.606, test loss 1.1327, test acc 0.589, time 109.9 sec\n"],"name":"stdout"}]}]}
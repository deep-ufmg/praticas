{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"01.2 - Pooling.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"Ed03SC1Jm9Yy","colab_type":"text"},"source":["# Pooling\n","\n","Muitas vezes, ao processar imagens, queremos gradualmente reduzir a resolução espacial das representações aprendidas (*feature maps*), agregando informações de forma que, quanto mais aprofundarmos na rede, maior o campo receptivo (*receptive field*).\n","\n","Muitas vezes, a tarefa final é relacionada com alguma característica global da imagem como, por exemplo,  na tarefa de classificação de cenas.\n","Então, tipicamente, os neurônios da última camada devem conseguir captar informação da entrada como um todo.\n","Ao agregar gradualmente as informações, produzindo *feature maps* de baixa resolução, alcançamos esse objetivo de aprender uma representação global, mantendo todas as vantagens das camadas convolucionais nas camadas intermediárias de processamento.\n","\n","Além disso, ao detectar características de baixo nível, como bordas, muitas vezes queremos que as representações sejam um pouco invariantes à translação.\n","Por exemplo, suponha uma imagem com uma definição nítida entre preto e branco.\n","Suponha agora que deslocamos toda a imagem em um pixel para a direita.\n","A saída para essa nova imagem pode ser muito diferente.\n","A borda terá mudado em um pixel e, consequentemente, todas as ativações mudarão.\n","Na realidade, os objetos quase nunca ocorrem exatamente no mesmo lugar.\n","De fato, mesmo com um tripé e um objeto estacionário, vibração da câmera devido ao movimento do obturador pode mudar tudo por um pixel ou mais .\n","\n","Nesta prática, veremos as camadas de pooling que tem dois própositos básicas: (i) tornar a representação invariante à translação, e (ii) reduzir espacialmente as características aprendidas, aumentando o *receptive field*.\n","\n","## Max- e Mean-Pooling\n","\n","Como camadas convolucionais, operadores de pooling consistem em uma janela (de tamanho fixo) deslizando sobre todas as regiões na entrada de acordo com seu *stride*, computando uma única saída para cada local visitado.\n","No entanto, ao contrário das camadas convolucionais, a camada de pooling não tem parâmetros (ou seja, ela não aprende nada).\n","Em vez disso, os operadores de pooling são determinísticos, normalmente calculando o valor máximo (*max*) ou médio (*mean*) dos elementos compreendido na sua janela.\n","Essas operações são chamadas de *max-pooling* e *mean-pooling*, respectivamente.\n","\n","Em ambos os casos, como na convolução, podemos pensar que o processo de pooling começa com sua janela no canto superior esquerdo da entrada e a desliza da esquerda para a direita e de cima para baixo.\n","Em cada vizinhança delimitada pela janela, calcula-se o valor máximo ou médio dos pixels daquela região.\n","\n","<p align=\"center\">\n","  <img src=\"https://drive.google.com/uc?export=view&id=17YzoYsvNPAX9OVeSGVIWeiGmsixeywF7\">\n","</p>\n","\n","O array de saída da figura acima tem uma altura de 2 e uma largura de 2.\n","Os quatro elementos são derivados do valor de máximo da vizinhança, ou seja:\n","\n","$$\n","\\max (0,1,3,4) = 4, \\\\\n","\\max (1,2,4,5) = 5, \\\\\n","\\max (3,4,6,7) = 7, \\\\\n","\\max (4,5,7,8) = 8. \\\\\n","$$\n","\n","Vamos retornar ao exemplo de detecção de borda de objeto mencionado no início desta seção. Agora vamos usar a saída da camada convolucional como a entrada para um max-pooling $ 2\\times 2$.\n","Mesmo se a entrada para a camada convolucional se transladar um pixel para qualquer lado, a camada de pooling será capaz de gerar a mesma saída, já que avaliará a vizinhança para produzir a saída.\n","Ou seja, usando uma camada de max-pooling de $2\\times 2$, ainda podemos detectar o padrão reconhecido pela camada convolucional dado que este não se mova mais do que um pixel em altura e largura."]},{"cell_type":"markdown","metadata":{"id":"Gp6CwWnFnTwb","colab_type":"text"},"source":["Antes de começar, vamos instalar o MXNet. Esse pequeno bloco de código abaixo é usado somente para instalar o MXNet para CUDA 10. Execute esse bloco somente uma vez e ignore possíveis erros levantados durante a instalação.\n","\n","**ATENÇÃO: a alteração deste bloco pode implicar em problemas na execução dos blocos restantes!**"]},{"cell_type":"code","metadata":{"id":"XW-VATPAldgt","colab_type":"code","outputId":"c3160ab1-400f-4856-aca5-83c78dba63b6","executionInfo":{"status":"ok","timestamp":1562590621153,"user_tz":180,"elapsed":7531,"user":{"displayName":"Keiller Nogueira","photoUrl":"https://lh5.googleusercontent.com/-OSbB3k7-l84/AAAAAAAAAAI/AAAAAAAAAac/z8WNFFAmye0/s64/photo.jpg","userId":"03938009311988397527"}},"colab":{"base_uri":"https://localhost:8080/","height":164}},"source":["!pip install mxnet-cu100\n","\n","# imports basicos\n","import time, os, sys, numpy as np\n","import mxnet as mx\n","from mxnet import autograd, gluon, init, nd\n","from mxnet.gluon import loss as gloss, nn, utils as gutils, data as gdata\n","\n","# Tenta encontrar GPU\n","def try_gpu():\n","    try:\n","        ctx = mx.gpu()\n","        _ = nd.zeros((1,), ctx=ctx)\n","    except mx.base.MXNetError:\n","        ctx = mx.cpu()\n","    return ctx\n","\n","ctx = try_gpu()\n","ctx\n","\n","## carregando dados\n","\n","# código para carregar o dataset do Fashion-MNIST\n","# https://github.com/zalandoresearch/fashion-mnist\n","def load_data_fashion_mnist(batch_size, resize=None, root=os.path.join(\n","        '~', '.mxnet', 'datasets', 'fashion-mnist')):\n","    \"\"\"Download the Fashion-MNIST dataset and then load into memory.\"\"\"\n","    root = os.path.expanduser(root)\n","    transformer = []\n","    if resize:\n","        transformer += [gdata.vision.transforms.Resize(resize)]\n","    transformer += [gdata.vision.transforms.ToTensor()]\n","    transformer = gdata.vision.transforms.Compose(transformer)\n","\n","    mnist_train = gdata.vision.FashionMNIST(root=root, train=True)\n","    mnist_test = gdata.vision.FashionMNIST(root=root, train=False)\n","    num_workers = 0 if sys.platform.startswith('win32') else 4\n","\n","    train_iter = gdata.DataLoader(mnist_train.transform_first(transformer),\n","                                  batch_size, shuffle=True,\n","                                  num_workers=num_workers)\n","    test_iter = gdata.DataLoader(mnist_test.transform_first(transformer),\n","                                 batch_size, shuffle=False,\n","                                 num_workers=num_workers)\n","    return train_iter, test_iter\n","\n","# funções básicas\n","def _get_batch(batch, ctx):\n","    \"\"\"Return features and labels on ctx.\"\"\"\n","    features, labels = batch\n","    if labels.dtype != features.dtype:\n","        labels = labels.astype(features.dtype)\n","    return (gutils.split_and_load(features, ctx),\n","            gutils.split_and_load(labels, ctx), features.shape[0])\n","\n","# Função usada para calcular acurácia\n","def evaluate_accuracy(data_iter, net, loss, ctx=[mx.cpu()]):\n","    \"\"\"Evaluate accuracy of a model on the given data set.\"\"\"\n","    if isinstance(ctx, mx.Context):\n","        ctx = [ctx]\n","    acc_sum, n, l = nd.array([0]), 0, 0\n","    for batch in data_iter:\n","        features, labels, _ = _get_batch(batch, ctx)\n","        for X, y in zip(features, labels):\n","            # X, y = X.as_in_context(ctx), y.as_in_context(ctx)\n","            y = y.astype('float32')\n","            y_hat = net(X)\n","            l += loss(y_hat, y).sum()\n","            acc_sum += (y_hat.argmax(axis=1) == y).sum().copyto(mx.cpu())\n","            n += y.size\n","        acc_sum.wait_to_read()\n","    return acc_sum.asscalar() / n, l.asscalar() / n\n","  \n","# Função usada no treinamento e validação da rede\n","def train_validate(net, train_iter, test_iter, batch_size, trainer, loss, ctx,\n","                   num_epochs):\n","    print('training on', ctx)\n","    for epoch in range(num_epochs):\n","        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\n","        for X, y in train_iter:\n","            X, y = X.as_in_context(ctx), y.as_in_context(ctx)\n","            with autograd.record():\n","                y_hat = net(X)\n","                l = loss(y_hat, y).sum()\n","            l.backward()\n","            trainer.step(batch_size)\n","            y = y.astype('float32')\n","            train_l_sum += l.asscalar()\n","            train_acc_sum += (y_hat.argmax(axis=1) == y).sum().asscalar()\n","            n += y.size\n","        test_acc, test_loss = evaluate_accuracy(test_iter, net, loss, ctx)\n","        print('epoch %d, train loss %.4f, train acc %.3f, test loss %.4f, '\n","              'test acc %.3f, time %.1f sec'\n","              % (epoch + 1, train_l_sum / n, train_acc_sum / n, test_loss, \n","                 test_acc, time.time() - start))"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: mxnet-cu100 in /usr/local/lib/python3.6/dist-packages (1.4.1)\n","Requirement already satisfied: numpy<1.15.0,>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu100) (1.14.6)\n","Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu100) (0.8.4)\n","Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu100) (2.21.0)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-cu100) (1.24.3)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-cu100) (3.0.4)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-cu100) (2.8)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-cu100) (2019.6.16)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"aotaipH_MIn3","colab_type":"text"},"source":["Vamos agora, mostrar como funciona a camada de *pooling* na prática. Em frameworks modernos, camadas de *pooling* já vem implementadas e são fáceis de usar.\n","\n","Abaixo, criamos uma matriz 2-D e a processamos usando um [*max-pooling*](https://mxnet.incubator.apache.org/api/python/gluon/nn.html#mxnet.gluon.nn.MaxPool2D) de $2\\times 2$."]},{"cell_type":"code","metadata":{"id":"6XkMnm6PLqeg","colab_type":"code","outputId":"66cc4eb2-582f-4804-f2a9-1a89b6bf18ef","executionInfo":{"status":"ok","timestamp":1562537958508,"user_tz":180,"elapsed":588,"user":{"displayName":"Keiller Nogueira","photoUrl":"https://lh5.googleusercontent.com/-OSbB3k7-l84/AAAAAAAAAAI/AAAAAAAAAac/z8WNFFAmye0/s64/photo.jpg","userId":"03938009311988397527"}},"colab":{"base_uri":"https://localhost:8080/","height":182}},"source":["X = nd.array([[0, 1, 2], [3, 4, 5], [6, 7, 8]])\n","print(X)\n","X = X.reshape((1, 1) + X.shape)\n","\n","pool = nn.MaxPool2D(pool_size=2, strides=1)\n","y = pool(X)\n","\n","print(y)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\n","[[0. 1. 2.]\n"," [3. 4. 5.]\n"," [6. 7. 8.]]\n","<NDArray 3x3 @cpu(0)>\n","\n","[[[[4. 5.]\n","   [7. 8.]]]]\n","<NDArray 1x1x2x2 @cpu(0)>\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ErguWtCAMIHZ","colab_type":"text"},"source":["Podemos também processar a entrada usando um [*mean-pooling*](https://mxnet.incubator.apache.org/api/python/gluon/nn.html#mxnet.gluon.nn.AvgPool2D)."]},{"cell_type":"code","metadata":{"id":"AKXLgmcwLroz","colab_type":"code","outputId":"645cce7d-9ab9-4845-9f63-38d6a4927b87","executionInfo":{"status":"ok","timestamp":1562537960443,"user_tz":180,"elapsed":552,"user":{"displayName":"Keiller Nogueira","photoUrl":"https://lh5.googleusercontent.com/-OSbB3k7-l84/AAAAAAAAAAI/AAAAAAAAAac/z8WNFFAmye0/s64/photo.jpg","userId":"03938009311988397527"}},"colab":{"base_uri":"https://localhost:8080/","height":182}},"source":["X = nd.array([[0, 1, 2], [3, 4, 5], [6, 7, 8]])\n","print(X)\n","X = X.reshape((1, 1) + X.shape)\n","\n","pool = nn.AvgPool2D(pool_size=2, strides=1)\n","y = pool(X)\n","\n","print(y)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\n","[[0. 1. 2.]\n"," [3. 4. 5.]\n"," [6. 7. 8.]]\n","<NDArray 3x3 @cpu(0)>\n","\n","[[[[2. 3.]\n","   [5. 6.]]]]\n","<NDArray 1x1x2x2 @cpu(0)>\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"uElQTLEUMcCT","colab_type":"text"},"source":["Ao processar dados com múltiplos canais, a camada de pooling processa cada canal de entrada separadamente ao invés de processar todos os canais como em uma camada convolucional.\n","Isso significa que o número de canais de saída para a camada de pooling é o mesmo que o número de canais de entrada.\n","Abaixo, vamos concatenar X e X + 1 na dimensão do canal para construir uma entrada com 2 canais."]},{"cell_type":"code","metadata":{"id":"vkbgWrfBLyNi","colab_type":"code","outputId":"59007e00-ab07-45d3-b279-2d9e6680e8e0","executionInfo":{"status":"ok","timestamp":1562537962804,"user_tz":180,"elapsed":552,"user":{"displayName":"Keiller Nogueira","photoUrl":"https://lh5.googleusercontent.com/-OSbB3k7-l84/AAAAAAAAAAI/AAAAAAAAAac/z8WNFFAmye0/s64/photo.jpg","userId":"03938009311988397527"}},"colab":{"base_uri":"https://localhost:8080/","height":182}},"source":["X = nd.concat(X, X + 1, dim=1)\n","X"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\n","[[[[0. 1. 2.]\n","   [3. 4. 5.]\n","   [6. 7. 8.]]\n","\n","  [[1. 2. 3.]\n","   [4. 5. 6.]\n","   [7. 8. 9.]]]]\n","<NDArray 1x2x3x3 @cpu(0)>"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"JJS0KSU7LzNY","colab_type":"code","outputId":"45dc7dae-b1fe-439a-d6f1-f68dbaf6f462","executionInfo":{"status":"ok","timestamp":1562538105668,"user_tz":180,"elapsed":658,"user":{"displayName":"Keiller Nogueira","photoUrl":"https://lh5.googleusercontent.com/-OSbB3k7-l84/AAAAAAAAAAI/AAAAAAAAAac/z8WNFFAmye0/s64/photo.jpg","userId":"03938009311988397527"}},"colab":{"base_uri":"https://localhost:8080/","height":146}},"source":["pool2d = nn.MaxPool2D(2, strides=1)\n","pool2d(X)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\n","[[[[4. 5.]\n","   [7. 8.]]\n","\n","  [[5. 6.]\n","   [8. 9.]]]]\n","<NDArray 1x2x2x2 @cpu(0)>"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"2ieq0UEAMO7l","colab_type":"text"},"source":["## Padding and Stride\n","\n","Como nas camadas convolucionais, as camadas de pooling também pode alterar as dimensões da saída.\n","Da mesma forma que antes, podemos calcular a saída da camada baseada na sua configuração:\n","\n","\n","$$\\lfloor (n_h-k_h + p_h + s_h) / s_h \\rfloor \\times \\lfloor(n_w-k_w + p_w + s_w) / s_w \\rfloor$$\n","\n","E como antes, podemos configurar a operação para obter uma saída com dimensões desejadas usando *padding* e *stride*.\n","Podemos demonstrar a influência de *padding* e *stride* em camadas de pooling através da camada de max-pooling *MaxPool2D* do framework MXNet.\n","Primeiro, construímos um dado de entrada com dimensões (1, 1, 4, 4), onde as duas primeiras dimensões são o tamanho do *batch* e canal."]},{"cell_type":"code","metadata":{"id":"ORzrYoVeLtp-","colab_type":"code","outputId":"59c72386-974c-4f33-da86-de29538bce57","executionInfo":{"status":"ok","timestamp":1562538191281,"user_tz":180,"elapsed":559,"user":{"displayName":"Keiller Nogueira","photoUrl":"https://lh5.googleusercontent.com/-OSbB3k7-l84/AAAAAAAAAAI/AAAAAAAAAac/z8WNFFAmye0/s64/photo.jpg","userId":"03938009311988397527"}},"colab":{"base_uri":"https://localhost:8080/","height":127}},"source":["X = nd.arange(16).reshape((1, 1, 4, 4))\n","X"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\n","[[[[ 0.  1.  2.  3.]\n","   [ 4.  5.  6.  7.]\n","   [ 8.  9. 10. 11.]\n","   [12. 13. 14. 15.]]]]\n","<NDArray 1x1x4x4 @cpu(0)>"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"markdown","metadata":{"id":"fCnu9S3QMSls","colab_type":"text"},"source":["Por padrão, o *stride*  da *MaxPool2D* tem o mesmo tamanho da janela.\n","Por exemplo, abaixo usamos uma janela de tamanho (3, 3).\n","Como não especificamos explicitamente nenhum *stride*, obtemos um *stride* padrão de tamanho (3, 3)."]},{"cell_type":"code","metadata":{"id":"GBN44X0GLuzN","colab_type":"code","outputId":"90d0f27e-aef9-41dd-e9c4-afd4db7b0a98","executionInfo":{"status":"ok","timestamp":1562538192713,"user_tz":180,"elapsed":557,"user":{"displayName":"Keiller Nogueira","photoUrl":"https://lh5.googleusercontent.com/-OSbB3k7-l84/AAAAAAAAAAI/AAAAAAAAAac/z8WNFFAmye0/s64/photo.jpg","userId":"03938009311988397527"}},"colab":{"base_uri":"https://localhost:8080/","height":72}},"source":["pool2d = nn.MaxPool2D(3)\n","# Because there are no model parameters in the pooling layer, we do not need\n","# to call the parameter initialization function\n","pool2d(X)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\n","[[[[10.]]]]\n","<NDArray 1x1x1x1 @cpu(0)>"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"markdown","metadata":{"id":"3VqYJpgcMWoS","colab_type":"text"},"source":["Logicamente, podemos especificar explicitamente o *padding* e o *stride* de uma camada de pooling."]},{"cell_type":"code","metadata":{"id":"LzZM7tRILv2V","colab_type":"code","outputId":"2d21fcd9-2632-439a-a7aa-72a18aeced9a","executionInfo":{"status":"ok","timestamp":1562538200654,"user_tz":180,"elapsed":568,"user":{"displayName":"Keiller Nogueira","photoUrl":"https://lh5.googleusercontent.com/-OSbB3k7-l84/AAAAAAAAAAI/AAAAAAAAAac/z8WNFFAmye0/s64/photo.jpg","userId":"03938009311988397527"}},"colab":{"base_uri":"https://localhost:8080/","height":90}},"source":["pool2d = nn.MaxPool2D(3, padding=1, strides=2)\n","pool2d(X)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\n","[[[[ 5.  7.]\n","   [13. 15.]]]]\n","<NDArray 1x1x2x2 @cpu(0)>"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"markdown","metadata":{"id":"9sxR165zMX0c","colab_type":"text"},"source":["Podemos, também, especificar o tamanho de uma janela retangular arbitrária, do *padding* e do *stride* para altura e largura, respectivamente."]},{"cell_type":"code","metadata":{"id":"jtDvTyYbLw73","colab_type":"code","outputId":"e5d4aba5-ca11-4343-97cd-6f39647bdde5","executionInfo":{"status":"ok","timestamp":1562538206893,"user_tz":180,"elapsed":538,"user":{"displayName":"Keiller Nogueira","photoUrl":"https://lh5.googleusercontent.com/-OSbB3k7-l84/AAAAAAAAAAI/AAAAAAAAAac/z8WNFFAmye0/s64/photo.jpg","userId":"03938009311988397527"}},"colab":{"base_uri":"https://localhost:8080/","height":109}},"source":["pool2d = nn.MaxPool2D((2, 3), padding=(1, 2), strides=(2, 3))\n","pool2d(X)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\n","[[[[ 0.  3.]\n","   [ 8. 11.]\n","   [12. 15.]]]]\n","<NDArray 1x1x3x2 @cpu(0)>"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"markdown","metadata":{"id":"D3wyY425JNtL","colab_type":"text"},"source":["## MXNet e o caso de estudo LeNet-5\n","\n","Agora vamos implementar a [LeNet-5](https://ieeexplore.ieee.org/document/726791) completa usando MXNet.\n","\n","<p align=\"center\">\n","  <img width=700 src=\"https://miro.medium.com/max/2625/1*1TI1aGBZ4dybR6__DI9dzA.png\">\n","</p>\n","\n","<p align=\"center\">\n","  <img width=700 src=\"https://engmrk.com/wp-content/uploads/2018/09/LeNEt_Summary_Table.jpg\">\n","</p>"]},{"cell_type":"code","metadata":{"id":"BJfhoDqJJjkY","colab_type":"code","outputId":"efa947a2-9ba0-4567-96a7-afdb81ef6c5d","executionInfo":{"status":"ok","timestamp":1562591027558,"user_tz":180,"elapsed":97238,"user":{"displayName":"Keiller Nogueira","photoUrl":"https://lh5.googleusercontent.com/-OSbB3k7-l84/AAAAAAAAAAI/AAAAAAAAAac/z8WNFFAmye0/s64/photo.jpg","userId":"03938009311988397527"}},"colab":{"base_uri":"https://localhost:8080/","height":219}},"source":["# parâmetros: número de epochs, learning rate (ou taxa de aprendizado), \n","# tamanho do batch, e lambda do weight decay\n","num_epochs, lr, batch_size, wd_lambda = 10, 0.1, 128, 0.000001\n","\n","# rede baseada na LeNet-5 \n","net = nn.Sequential()\n","net.add(nn.Conv2D(6, kernel_size=5, strides=1, padding=0, activation='tanh'),   # entrada: (b, 1, 32, 32) e saida: (b, 6, 28, 28)\n","        nn.AvgPool2D(pool_size=2, strides=2, padding=0),                        # entrada: (b, 6, 28, 28) e saida: (b, 6, 14, 14)\n","        nn.Conv2D(16, kernel_size=5, strides=1, padding=0, activation='tanh'),  # entrada: (b, 6, 14, 14) e saida: (b, 16, 10, 10)\n","        nn.AvgPool2D(pool_size=2, strides=2, padding=0),                        # entrada: (b, 16, 10, 10) e saida: (b, 16, 5, 5)\n","        nn.Conv2D(120, kernel_size=5, strides=1, padding=0, activation='tanh'), # entrada: (b, 16, 5, 5) e saida: (b, 120, 1, 1)\n","        nn.Flatten(),  # lineariza formando um vetor                            # entrada: (b, 120, 1, 1) e saida: (b, 120*1*1) = (b, 120)\n","        nn.Dense(84, activation=\"tanh\"),                                        # entrada: (b, 120) e saida: (b, 84)\n","        nn.Dense(10))                                                           # entrada: (b, 84) e saida: (b, 10)\n","net.initialize(init.Normal(sigma=0.01), ctx=ctx)\n","\n","# função de custo (ou loss)\n","loss = gloss.SoftmaxCrossEntropyLoss()\n","\n","# carregamento do dado: mnist\n","train_iter, test_iter = load_data_fashion_mnist(batch_size, resize=32)\n","\n","# trainer do gluon\n","trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': lr, 'wd': wd_lambda, 'momentum': 0.9})\n","\n","# treinamento e validação via MXNet\n","train_validate(net, train_iter, test_iter, batch_size, trainer, loss, \n","               ctx, num_epochs)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["training on gpu(0)\n","epoch 1, train loss 2.3040, train acc 0.101, test loss 2.3052, test acc 0.100, time 10.0 sec\n","epoch 2, train loss 0.9554, train acc 0.624, test loss 0.4549, test acc 0.837, time 9.4 sec\n","epoch 3, train loss 0.4368, train acc 0.839, test loss 0.4411, test acc 0.836, time 9.7 sec\n","epoch 4, train loss 0.3819, train acc 0.861, test loss 0.3565, test acc 0.867, time 9.3 sec\n","epoch 5, train loss 0.3491, train acc 0.872, test loss 0.3400, test acc 0.874, time 9.6 sec\n","epoch 6, train loss 0.3261, train acc 0.880, test loss 0.3271, test acc 0.874, time 9.8 sec\n","epoch 7, train loss 0.3060, train acc 0.886, test loss 0.3206, test acc 0.881, time 9.7 sec\n","epoch 8, train loss 0.2939, train acc 0.892, test loss 0.3071, test acc 0.887, time 9.5 sec\n","epoch 9, train loss 0.2787, train acc 0.897, test loss 0.2935, test acc 0.893, time 9.1 sec\n","epoch 10, train loss 0.2707, train acc 0.901, test loss 0.2984, test acc 0.889, time 9.5 sec\n"],"name":"stdout"}]}]}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "S05A04_1 - Pytorch GANs.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXs-3iyk2e3l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -r PyTorch-GAN\n",
        "!git clone https://github.com/eriklindernoren/PyTorch-GAN\n",
        "%cd /content/PyTorch-GAN/\n",
        "!sudo pip3 install -r requirements.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7D04c3ESmEM",
        "colab_type": "text"
      },
      "source": [
        "# InfoGAN\n",
        "\n",
        "Variando um bin contínuo:\n",
        "\n",
        "![InfoGAN](https://github.com/eriklindernoren/PyTorch-GAN/raw/master/assets/infogan.gif)\n",
        "\n",
        "Variando um bin categórico:\n",
        "\n",
        "![InfoGAN](https://github.com/eriklindernoren/PyTorch-GAN/raw/master/assets/infogan.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGHl_MbtSnwM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/PyTorch-GAN/\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "%cd /content/PyTorch-GAN/implementations/infogan/\n",
        "\n",
        "import argparse\n",
        "import os\n",
        "import numpy as np\n",
        "import math\n",
        "import itertools\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "os.makedirs(\"images/static/\", exist_ok=True)\n",
        "os.makedirs(\"images/varying_c1/\", exist_ok=True)\n",
        "os.makedirs(\"images/varying_c2/\", exist_ok=True)\n",
        "\n",
        "\n",
        "class Opt:\n",
        "    epoch = 1\n",
        "    n_epochs = 100\n",
        "    batch_size = 100\n",
        "    lr = 0.0002\n",
        "    b1 = 0.5\n",
        "    b2 = 0.999\n",
        "    n_cpu = 4\n",
        "    latent_dim = 62\n",
        "    code_dim = 2\n",
        "    n_classes = 10\n",
        "    img_size = 32\n",
        "    channels = 1\n",
        "    sample_interval = 200\n",
        "\n",
        "opt = Opt()\n",
        "\n",
        "print(opt)\n",
        "\n",
        "cuda = True if torch.cuda.is_available() else False\n",
        "\n",
        "\n",
        "def weights_init_normal(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find(\"Conv\") != -1:\n",
        "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find(\"BatchNorm\") != -1:\n",
        "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        torch.nn.init.constant_(m.bias.data, 0.0)\n",
        "\n",
        "\n",
        "def to_categorical(y, num_columns):\n",
        "    \"\"\"Returns one-hot encoded Variable\"\"\"\n",
        "    y_cat = np.zeros((y.shape[0], num_columns))\n",
        "    y_cat[range(y.shape[0]), y] = 1.0\n",
        "\n",
        "    return Variable(FloatTensor(y_cat))\n",
        "\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        input_dim = opt.latent_dim + opt.n_classes + opt.code_dim\n",
        "\n",
        "        self.init_size = opt.img_size // 4  # Initial size before upsampling\n",
        "        self.l1 = nn.Sequential(nn.Linear(input_dim, 128 * self.init_size ** 2))\n",
        "\n",
        "        self.conv_blocks = nn.Sequential(\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(128, 128, 3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(128, 0.8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(128, 64, 3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64, 0.8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(64, opt.channels, 3, stride=1, padding=1),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "\n",
        "    def forward(self, noise, labels, code):\n",
        "        gen_input = torch.cat((noise, labels, code), -1)\n",
        "        out = self.l1(gen_input)\n",
        "        out = out.view(out.shape[0], 128, self.init_size, self.init_size)\n",
        "        img = self.conv_blocks(out)\n",
        "        return img\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        def discriminator_block(in_filters, out_filters, bn=True):\n",
        "            \"\"\"Returns layers of each discriminator block\"\"\"\n",
        "            block = [nn.Conv2d(in_filters, out_filters, 3, 2, 1), nn.LeakyReLU(0.2, inplace=True), nn.Dropout2d(0.25)]\n",
        "            if bn:\n",
        "                block.append(nn.BatchNorm2d(out_filters, 0.8))\n",
        "            return block\n",
        "\n",
        "        self.conv_blocks = nn.Sequential(\n",
        "            *discriminator_block(opt.channels, 16, bn=False),\n",
        "            *discriminator_block(16, 32),\n",
        "            *discriminator_block(32, 64),\n",
        "            *discriminator_block(64, 128),\n",
        "        )\n",
        "\n",
        "        # The height and width of downsampled image\n",
        "        ds_size = opt.img_size // 2 ** 4\n",
        "\n",
        "        # Output layers\n",
        "        self.adv_layer = nn.Sequential(nn.Linear(128 * ds_size ** 2, 1))\n",
        "        self.aux_layer = nn.Sequential(nn.Linear(128 * ds_size ** 2, opt.n_classes), nn.Softmax())\n",
        "        self.latent_layer = nn.Sequential(nn.Linear(128 * ds_size ** 2, opt.code_dim))\n",
        "\n",
        "    def forward(self, img):\n",
        "        out = self.conv_blocks(img)\n",
        "        out = out.view(out.shape[0], -1)\n",
        "        validity = self.adv_layer(out)\n",
        "        label = self.aux_layer(out)\n",
        "        latent_code = self.latent_layer(out)\n",
        "\n",
        "        return validity, label, latent_code\n",
        "\n",
        "\n",
        "# Loss functions\n",
        "adversarial_loss = torch.nn.MSELoss()\n",
        "categorical_loss = torch.nn.CrossEntropyLoss()\n",
        "continuous_loss = torch.nn.MSELoss()\n",
        "\n",
        "# Loss weights\n",
        "lambda_cat = 1\n",
        "lambda_con = 0.1\n",
        "\n",
        "# Initialize generator and discriminator\n",
        "generator = Generator()\n",
        "discriminator = Discriminator()\n",
        "\n",
        "if cuda:\n",
        "    generator.cuda()\n",
        "    discriminator.cuda()\n",
        "    adversarial_loss.cuda()\n",
        "    categorical_loss.cuda()\n",
        "    continuous_loss.cuda()\n",
        "\n",
        "# Initialize weights\n",
        "generator.apply(weights_init_normal)\n",
        "discriminator.apply(weights_init_normal)\n",
        "\n",
        "# Configure data loader\n",
        "os.makedirs(\"../../data/mnist\", exist_ok=True)\n",
        "dataloader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST(\n",
        "        \"../../data/mnist\",\n",
        "        train=True,\n",
        "        download=True,\n",
        "        transform=transforms.Compose(\n",
        "            [transforms.Resize(opt.img_size), transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]\n",
        "        ),\n",
        "    ),\n",
        "    batch_size=opt.batch_size,\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "# Optimizers\n",
        "optimizer_G = torch.optim.Adam(generator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
        "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
        "optimizer_info = torch.optim.Adam(\n",
        "    itertools.chain(generator.parameters(), discriminator.parameters()), lr=opt.lr, betas=(opt.b1, opt.b2)\n",
        ")\n",
        "\n",
        "FloatTensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
        "LongTensor = torch.cuda.LongTensor if cuda else torch.LongTensor\n",
        "\n",
        "# Static generator inputs for sampling\n",
        "static_z = Variable(FloatTensor(np.zeros((opt.n_classes ** 2, opt.latent_dim))))\n",
        "static_label = to_categorical(\n",
        "    np.array([num for _ in range(opt.n_classes) for num in range(opt.n_classes)]), num_columns=opt.n_classes\n",
        ")\n",
        "static_code = Variable(FloatTensor(np.zeros((opt.n_classes ** 2, opt.code_dim))))\n",
        "\n",
        "\n",
        "def sample_image(n_row, batches_done):\n",
        "    \"\"\"Saves a grid of generated digits ranging from 0 to n_classes\"\"\"\n",
        "    # Static sample\n",
        "    z = Variable(FloatTensor(np.random.normal(0, 1, (n_row ** 2, opt.latent_dim))))\n",
        "    static_sample = generator(z, static_label, static_code)\n",
        "    save_image(static_sample.data, \"images/static/%d.png\" % batches_done, nrow=n_row, normalize=True)\n",
        "\n",
        "    # Get varied c1 and c2\n",
        "    zeros = np.zeros((n_row ** 2, 1))\n",
        "    c_varied = np.repeat(np.linspace(-1, 1, n_row)[:, np.newaxis], n_row, 0)\n",
        "    c1 = Variable(FloatTensor(np.concatenate((c_varied, zeros), -1)))\n",
        "    c2 = Variable(FloatTensor(np.concatenate((zeros, c_varied), -1)))\n",
        "    sample1 = generator(static_z, static_label, c1)\n",
        "    sample2 = generator(static_z, static_label, c2)\n",
        "    save_image(sample1.data, \"images/varying_c1/%d.png\" % batches_done, nrow=n_row, normalize=True)\n",
        "    save_image(sample2.data, \"images/varying_c2/%d.png\" % batches_done, nrow=n_row, normalize=True)\n",
        "    \n",
        "    # Plotting.\n",
        "    fig, ax = plt.subplots(2, 19, figsize=(20, 2))\n",
        "\n",
        "    for i in range(19):\n",
        "        \n",
        "        ax[0, i].imshow(sample1[i * 5].detach().cpu().numpy().squeeze())\n",
        "        ax[0, i].set_yticks([])\n",
        "        ax[0, i].set_xticks([])\n",
        "        \n",
        "        ax[1, i].imshow(sample2[i * 5].detach().cpu().numpy().squeeze())\n",
        "        ax[1, i].set_yticks([])\n",
        "        ax[1, i].set_xticks([])\n",
        "    \n",
        "    plt.show()\n",
        "\n",
        "# ----------\n",
        "#  Training\n",
        "# ----------\n",
        "\n",
        "for epoch in range(opt.n_epochs):\n",
        "    for i, (imgs, labels) in enumerate(dataloader):\n",
        "\n",
        "        batch_size = imgs.shape[0]\n",
        "\n",
        "        # Adversarial ground truths\n",
        "        valid = Variable(FloatTensor(batch_size, 1).fill_(1.0), requires_grad=False)\n",
        "        fake = Variable(FloatTensor(batch_size, 1).fill_(0.0), requires_grad=False)\n",
        "\n",
        "        # Configure input\n",
        "        real_imgs = Variable(imgs.type(FloatTensor))\n",
        "        labels = to_categorical(labels.numpy(), num_columns=opt.n_classes)\n",
        "\n",
        "        # -----------------\n",
        "        #  Train Generator\n",
        "        # -----------------\n",
        "\n",
        "        optimizer_G.zero_grad()\n",
        "\n",
        "        # Sample noise and labels as generator input\n",
        "        z = Variable(FloatTensor(np.random.normal(0, 1, (batch_size, opt.latent_dim))))\n",
        "        label_input = to_categorical(np.random.randint(0, opt.n_classes, batch_size), num_columns=opt.n_classes)\n",
        "        code_input = Variable(FloatTensor(np.random.uniform(-1, 1, (batch_size, opt.code_dim))))\n",
        "\n",
        "        # Generate a batch of images\n",
        "        gen_imgs = generator(z, label_input, code_input)\n",
        "\n",
        "        # Loss measures generator's ability to fool the discriminator\n",
        "        validity, _, _ = discriminator(gen_imgs)\n",
        "        g_loss = adversarial_loss(validity, valid)\n",
        "\n",
        "        g_loss.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "        # ---------------------\n",
        "        #  Train Discriminator\n",
        "        # ---------------------\n",
        "\n",
        "        optimizer_D.zero_grad()\n",
        "\n",
        "        # Loss for real images\n",
        "        real_pred, _, _ = discriminator(real_imgs)\n",
        "        d_real_loss = adversarial_loss(real_pred, valid)\n",
        "\n",
        "        # Loss for fake images\n",
        "        fake_pred, _, _ = discriminator(gen_imgs.detach())\n",
        "        d_fake_loss = adversarial_loss(fake_pred, fake)\n",
        "\n",
        "        # Total discriminator loss\n",
        "        d_loss = (d_real_loss + d_fake_loss) / 2\n",
        "\n",
        "        d_loss.backward()\n",
        "        optimizer_D.step()\n",
        "\n",
        "        # ------------------\n",
        "        # Information Loss\n",
        "        # ------------------\n",
        "\n",
        "        optimizer_info.zero_grad()\n",
        "\n",
        "        # Sample labels\n",
        "        sampled_labels = np.random.randint(0, opt.n_classes, batch_size)\n",
        "\n",
        "        # Ground truth labels\n",
        "        gt_labels = Variable(LongTensor(sampled_labels), requires_grad=False)\n",
        "\n",
        "        # Sample noise, labels and code as generator input\n",
        "        z = Variable(FloatTensor(np.random.normal(0, 1, (batch_size, opt.latent_dim))))\n",
        "        label_input = to_categorical(sampled_labels, num_columns=opt.n_classes)\n",
        "        code_input = Variable(FloatTensor(np.random.uniform(-1, 1, (batch_size, opt.code_dim))))\n",
        "\n",
        "        gen_imgs = generator(z, label_input, code_input)\n",
        "        _, pred_label, pred_code = discriminator(gen_imgs)\n",
        "\n",
        "        info_loss = lambda_cat * categorical_loss(pred_label, gt_labels) + lambda_con * continuous_loss(\n",
        "            pred_code, code_input\n",
        "        )\n",
        "\n",
        "        info_loss.backward()\n",
        "        optimizer_info.step()\n",
        "\n",
        "        # --------------\n",
        "        # Log Progress\n",
        "        # --------------\n",
        "\n",
        "        batches_done = epoch * len(dataloader) + i\n",
        "        if batches_done % opt.sample_interval == 0:\n",
        "            \n",
        "            print(\n",
        "                \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f] [info loss: %f]\"\n",
        "                % (epoch, opt.n_epochs, i, len(dataloader), d_loss.item(), g_loss.item(), info_loss.item())\n",
        "            )\n",
        "            \n",
        "            sample_image(n_row=10, batches_done=batches_done)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpG5u7dlPchb",
        "colab_type": "text"
      },
      "source": [
        "# Coupled GANs\n",
        "\n",
        "![CoGANs Architecture](https://www.dropbox.com/s/gb8reenksoat279/CoGANs.png?dl=1)\n",
        "\n",
        "![CoGANs](https://github.com/eriklindernoren/PyTorch-GAN/raw/master/assets/cogan.gif)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqA_VpnMPf55",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/PyTorch-GAN/\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "%cd /content/PyTorch-GAN/implementations/cogan/\n",
        "\n",
        "import argparse\n",
        "import os\n",
        "import numpy as np\n",
        "import math\n",
        "import scipy\n",
        "import itertools\n",
        "\n",
        "import mnistm\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "\n",
        "os.makedirs(\"images\", exist_ok=True)\n",
        "\n",
        "class Opt:\n",
        "    epoch = 1\n",
        "    n_epochs = 100\n",
        "    batch_size = 500\n",
        "    dataset_name = 'facades'\n",
        "    lr = 0.0002\n",
        "    b1 = 0.5\n",
        "    b2 = 0.999\n",
        "    n_cpu = 4\n",
        "    latent_dim = 100\n",
        "    img_size = 32\n",
        "    channels = 3\n",
        "    sample_interval = 500\n",
        "\n",
        "opt = Opt()\n",
        "\n",
        "print(opt)\n",
        "\n",
        "img_shape = (opt.channels, opt.img_size, opt.img_size)\n",
        "\n",
        "cuda = True if torch.cuda.is_available() else False\n",
        "\n",
        "\n",
        "def weights_init_normal(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find(\"Linear\") != -1:\n",
        "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find(\"BatchNorm\") != -1:\n",
        "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        torch.nn.init.constant_(m.bias.data, 0.0)\n",
        "\n",
        "\n",
        "class CoupledGenerators(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CoupledGenerators, self).__init__()\n",
        "\n",
        "        self.init_size = opt.img_size // 4\n",
        "        self.fc = nn.Sequential(nn.Linear(opt.latent_dim, 128 * self.init_size ** 2))\n",
        "\n",
        "        self.shared_conv = nn.Sequential(\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(128, 128, 3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(128, 0.8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "        )\n",
        "        self.G1 = nn.Sequential(\n",
        "            nn.Conv2d(128, 64, 3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64, 0.8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(64, opt.channels, 3, stride=1, padding=1),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "        self.G2 = nn.Sequential(\n",
        "            nn.Conv2d(128, 64, 3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64, 0.8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(64, opt.channels, 3, stride=1, padding=1),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "\n",
        "    def forward(self, noise):\n",
        "        out = self.fc(noise)\n",
        "        out = out.view(out.shape[0], 128, self.init_size, self.init_size)\n",
        "        img_emb = self.shared_conv(out)\n",
        "        img1 = self.G1(img_emb)\n",
        "        img2 = self.G2(img_emb)\n",
        "        return img1, img2\n",
        "\n",
        "\n",
        "class CoupledDiscriminators(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CoupledDiscriminators, self).__init__()\n",
        "\n",
        "        def discriminator_block(in_filters, out_filters, bn=True):\n",
        "            block = [nn.Conv2d(in_filters, out_filters, 3, 2, 1)]\n",
        "            if bn:\n",
        "                block.append(nn.BatchNorm2d(out_filters, 0.8))\n",
        "            block.extend([nn.LeakyReLU(0.2, inplace=True), nn.Dropout2d(0.25)])\n",
        "            return block\n",
        "\n",
        "        self.shared_conv = nn.Sequential(\n",
        "            *discriminator_block(opt.channels, 16, bn=False),\n",
        "            *discriminator_block(16, 32),\n",
        "            *discriminator_block(32, 64),\n",
        "            *discriminator_block(64, 128),\n",
        "        )\n",
        "        # The height and width of downsampled image\n",
        "        ds_size = opt.img_size // 2 ** 4\n",
        "        self.D1 = nn.Linear(128 * ds_size ** 2, 1)\n",
        "        self.D2 = nn.Linear(128 * ds_size ** 2, 1)\n",
        "\n",
        "    def forward(self, img1, img2):\n",
        "        # Determine validity of first image\n",
        "        out = self.shared_conv(img1)\n",
        "        out = out.view(out.shape[0], -1)\n",
        "        validity1 = self.D1(out)\n",
        "        # Determine validity of second image\n",
        "        out = self.shared_conv(img2)\n",
        "        out = out.view(out.shape[0], -1)\n",
        "        validity2 = self.D2(out)\n",
        "\n",
        "        return validity1, validity2\n",
        "\n",
        "\n",
        "# Loss function\n",
        "adversarial_loss = torch.nn.MSELoss()\n",
        "\n",
        "# Initialize models\n",
        "coupled_generators = CoupledGenerators()\n",
        "coupled_discriminators = CoupledDiscriminators()\n",
        "\n",
        "if cuda:\n",
        "    coupled_generators.cuda()\n",
        "    coupled_discriminators.cuda()\n",
        "\n",
        "# Initialize weights\n",
        "coupled_generators.apply(weights_init_normal)\n",
        "coupled_discriminators.apply(weights_init_normal)\n",
        "\n",
        "# Configure data loader\n",
        "os.makedirs(\"../../data/mnist\", exist_ok=True)\n",
        "dataloader1 = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST(\n",
        "        \"../../data/mnist\",\n",
        "        train=True,\n",
        "        download=True,\n",
        "        transform=transforms.Compose(\n",
        "            [transforms.Resize(opt.img_size), transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]\n",
        "        ),\n",
        "    ),\n",
        "    batch_size=opt.batch_size,\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "os.makedirs(\"../../data/mnistm\", exist_ok=True)\n",
        "dataloader2 = torch.utils.data.DataLoader(\n",
        "    mnistm.MNISTM(\n",
        "        \"../../data/mnistm\",\n",
        "        train=True,\n",
        "        download=True,\n",
        "        transform=transforms.Compose(\n",
        "            [\n",
        "                transforms.Resize(opt.img_size),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "            ]\n",
        "        ),\n",
        "    ),\n",
        "    batch_size=opt.batch_size,\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "# Optimizers\n",
        "optimizer_G = torch.optim.Adam(coupled_generators.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
        "optimizer_D = torch.optim.Adam(coupled_discriminators.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
        "\n",
        "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
        "\n",
        "# ----------\n",
        "#  Training\n",
        "# ----------\n",
        "\n",
        "for epoch in range(opt.n_epochs):\n",
        "    \n",
        "    for i, ((imgs1, _), (imgs2, _)) in enumerate(zip(dataloader1, dataloader2)):\n",
        "\n",
        "        batch_size = imgs1.shape[0]\n",
        "\n",
        "        # Adversarial ground truths\n",
        "        valid = Variable(Tensor(batch_size, 1).fill_(1.0), requires_grad=False)\n",
        "        fake = Variable(Tensor(batch_size, 1).fill_(0.0), requires_grad=False)\n",
        "\n",
        "        # Configure input\n",
        "        imgs1 = Variable(imgs1.type(Tensor).expand(imgs1.size(0), 3, opt.img_size, opt.img_size))\n",
        "        imgs2 = Variable(imgs2.type(Tensor))\n",
        "\n",
        "        # ------------------\n",
        "        #  Train Generators\n",
        "        # ------------------\n",
        "\n",
        "        optimizer_G.zero_grad()\n",
        "\n",
        "        # Sample noise as generator input\n",
        "        z = Variable(Tensor(np.random.normal(0, 1, (batch_size, opt.latent_dim))))\n",
        "\n",
        "        # Generate a batch of images\n",
        "        gen_imgs1, gen_imgs2 = coupled_generators(z)\n",
        "        # Determine validity of generated images\n",
        "        validity1, validity2 = coupled_discriminators(gen_imgs1, gen_imgs2)\n",
        "\n",
        "        g_loss = (adversarial_loss(validity1, valid) + adversarial_loss(validity2, valid)) / 2\n",
        "\n",
        "        g_loss.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "        # ----------------------\n",
        "        #  Train Discriminators\n",
        "        # ----------------------\n",
        "\n",
        "        optimizer_D.zero_grad()\n",
        "\n",
        "        # Determine validity of real and generated images\n",
        "        validity1_real, validity2_real = coupled_discriminators(imgs1, imgs2)\n",
        "        validity1_fake, validity2_fake = coupled_discriminators(gen_imgs1.detach(), gen_imgs2.detach())\n",
        "\n",
        "        d_loss = (\n",
        "            adversarial_loss(validity1_real, valid)\n",
        "            + adversarial_loss(validity1_fake, fake)\n",
        "            + adversarial_loss(validity2_real, valid)\n",
        "            + adversarial_loss(validity2_fake, fake)\n",
        "        ) / 4\n",
        "\n",
        "        d_loss.backward()\n",
        "        optimizer_D.step()\n",
        "\n",
        "        batches_done = epoch * len(dataloader1) + i\n",
        "        if batches_done % opt.sample_interval == 0:\n",
        "\n",
        "            print(\n",
        "                \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\"\n",
        "                % (epoch, opt.n_epochs, i, len(dataloader1), d_loss.item(), g_loss.item())\n",
        "            )\n",
        "            \n",
        "            gen_imgs = torch.cat((gen_imgs1.data, gen_imgs2.data), 0)\n",
        "            save_image(gen_imgs, \"images/%d.png\" % batches_done, nrow=8, normalize=True)\n",
        "            \n",
        "            \n",
        "            fig, ax = plt.subplots(2, 3, figsize=(12, 4))\n",
        "\n",
        "            ax[0, 0].imshow(gen_imgs1.data[0].cpu().numpy().transpose(1, 2, 0) * 0.5 + 0.5)\n",
        "            ax[0, 0].set_yticks([])\n",
        "            ax[0, 0].set_xticks([])\n",
        "            ax[0, 0].set_title('MNIST')\n",
        "\n",
        "            ax[0, 1].imshow(gen_imgs1.data[1].cpu().numpy().transpose(1, 2, 0) * 0.5 + 0.5)\n",
        "            ax[0, 1].set_yticks([])\n",
        "            ax[0, 1].set_xticks([])\n",
        "            ax[0, 1].set_title('MNIST')\n",
        "\n",
        "            ax[0, 2].imshow(gen_imgs1.data[2].cpu().numpy().transpose(1, 2, 0) * 0.5 + 0.5)\n",
        "            ax[0, 2].set_yticks([])\n",
        "            ax[0, 2].set_xticks([])\n",
        "            ax[0, 2].set_title('MNIST')\n",
        "\n",
        "            ax[1, 0].imshow(gen_imgs2.data[0].cpu().numpy().transpose(1, 2, 0) * 0.5 + 0.5)\n",
        "            ax[1, 0].set_yticks([])\n",
        "            ax[1, 0].set_xticks([])\n",
        "            ax[1, 0].set_title('MNIST')\n",
        "\n",
        "            ax[1, 1].imshow(gen_imgs2.data[1].cpu().numpy().transpose(1, 2, 0) * 0.5 + 0.5)\n",
        "            ax[1, 1].set_yticks([])\n",
        "            ax[1, 1].set_xticks([])\n",
        "            ax[1, 1].set_title('MNIST')\n",
        "\n",
        "            ax[1, 2].imshow(gen_imgs2.data[2].cpu().numpy().transpose(1, 2, 0) * 0.5 + 0.5)\n",
        "            ax[1, 2].set_yticks([])\n",
        "            ax[1, 2].set_xticks([])\n",
        "            ax[1, 2].set_title('MNIST')\n",
        "\n",
        "            plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZaC-TNwWPB_",
        "colab_type": "text"
      },
      "source": [
        "# DCGANs\n",
        "\n",
        "![DCGAN Architecture](https://miro.medium.com/max/700/1*KvMnRfb76DponICrHIbSdg.png)\n",
        "\n",
        "![DCGANs](https://github.com/eriklindernoren/PyTorch-GAN/raw/master/assets/dcgan.gif)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUNSFaxcWRl9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/PyTorch-GAN/\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "%cd /content/PyTorch-GAN/implementations/dcgan/\n",
        "\n",
        "import argparse\n",
        "import os\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "os.makedirs(\"images\", exist_ok=True)\n",
        "\n",
        "class Opt:\n",
        "    epoch = 1\n",
        "    n_epochs = 100\n",
        "    batch_size = 64\n",
        "    lr = 0.0002\n",
        "    b1 = 0.5\n",
        "    b2 = 0.999\n",
        "    n_cpu = 4\n",
        "    latent_dim = 100\n",
        "    img_size = 64\n",
        "    channels = 1\n",
        "    sample_interval = 400\n",
        "\n",
        "opt = Opt()\n",
        "\n",
        "print(opt)\n",
        "\n",
        "cuda = True if torch.cuda.is_available() else False\n",
        "\n",
        "\n",
        "def weights_init_normal(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find(\"Conv\") != -1:\n",
        "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find(\"BatchNorm2d\") != -1:\n",
        "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        torch.nn.init.constant_(m.bias.data, 0.0)\n",
        "\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        self.init_size = opt.img_size // 4\n",
        "        self.l1 = nn.Sequential(nn.Linear(opt.latent_dim, 128 * self.init_size ** 2))\n",
        "\n",
        "        self.conv_blocks = nn.Sequential(\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(128, 128, 3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(128, 0.8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(128, 64, 3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64, 0.8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(64, opt.channels, 3, stride=1, padding=1),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        out = self.l1(z)\n",
        "        out = out.view(out.shape[0], 128, self.init_size, self.init_size)\n",
        "        img = self.conv_blocks(out)\n",
        "        return img\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        def discriminator_block(in_filters, out_filters, bn=True):\n",
        "            block = [nn.Conv2d(in_filters, out_filters, 3, 2, 1), nn.LeakyReLU(0.2, inplace=True), nn.Dropout2d(0.25)]\n",
        "            if bn:\n",
        "                block.append(nn.BatchNorm2d(out_filters, 0.8))\n",
        "            return block\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            *discriminator_block(opt.channels, 16, bn=False),\n",
        "            *discriminator_block(16, 32),\n",
        "            *discriminator_block(32, 64),\n",
        "            *discriminator_block(64, 128),\n",
        "        )\n",
        "\n",
        "        # The height and width of downsampled image\n",
        "        ds_size = opt.img_size // 2 ** 4\n",
        "        self.adv_layer = nn.Sequential(nn.Linear(128 * ds_size ** 2, 1), nn.Sigmoid())\n",
        "\n",
        "    def forward(self, img):\n",
        "        out = self.model(img)\n",
        "        out = out.view(out.shape[0], -1)\n",
        "        validity = self.adv_layer(out)\n",
        "\n",
        "        return validity\n",
        "\n",
        "\n",
        "# Loss function\n",
        "adversarial_loss = torch.nn.BCELoss()\n",
        "\n",
        "# Initialize generator and discriminator\n",
        "generator = Generator()\n",
        "discriminator = Discriminator()\n",
        "\n",
        "if cuda:\n",
        "    generator.cuda()\n",
        "    discriminator.cuda()\n",
        "    adversarial_loss.cuda()\n",
        "\n",
        "# Initialize weights\n",
        "generator.apply(weights_init_normal)\n",
        "discriminator.apply(weights_init_normal)\n",
        "\n",
        "# Configure data loader\n",
        "os.makedirs(\"../../data/mnist\", exist_ok=True)\n",
        "dataloader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST(\n",
        "        \"../../data/mnist\",\n",
        "        train=True,\n",
        "        download=True,\n",
        "        transform=transforms.Compose(\n",
        "            [transforms.Resize(opt.img_size), transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]\n",
        "        ),\n",
        "    ),\n",
        "    batch_size=opt.batch_size,\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "# Optimizers\n",
        "optimizer_G = torch.optim.Adam(generator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
        "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
        "\n",
        "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
        "\n",
        "# ----------\n",
        "#  Training\n",
        "# ----------\n",
        "\n",
        "for epoch in range(opt.n_epochs):\n",
        "    for i, (imgs, _) in enumerate(dataloader):\n",
        "\n",
        "        # Adversarial ground truths\n",
        "        valid = Variable(Tensor(imgs.shape[0], 1).fill_(1.0), requires_grad=False)\n",
        "        fake = Variable(Tensor(imgs.shape[0], 1).fill_(0.0), requires_grad=False)\n",
        "\n",
        "        # Configure input\n",
        "        real_imgs = Variable(imgs.type(Tensor))\n",
        "\n",
        "        # -----------------\n",
        "        #  Train Generator\n",
        "        # -----------------\n",
        "\n",
        "        optimizer_G.zero_grad()\n",
        "\n",
        "        # Sample noise as generator input\n",
        "        z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], opt.latent_dim))))\n",
        "\n",
        "        # Generate a batch of images\n",
        "        gen_imgs = generator(z)\n",
        "\n",
        "        # Loss measures generator's ability to fool the discriminator\n",
        "        g_loss = adversarial_loss(discriminator(gen_imgs), valid)\n",
        "\n",
        "        g_loss.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "        # ---------------------\n",
        "        #  Train Discriminator\n",
        "        # ---------------------\n",
        "\n",
        "        optimizer_D.zero_grad()\n",
        "\n",
        "        # Measure discriminator's ability to classify real from generated samples\n",
        "        real_loss = adversarial_loss(discriminator(real_imgs), valid)\n",
        "        fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake)\n",
        "        d_loss = (real_loss + fake_loss) / 2\n",
        "\n",
        "        d_loss.backward()\n",
        "        optimizer_D.step()\n",
        "\n",
        "        batches_done = epoch * len(dataloader) + i\n",
        "        if batches_done % opt.sample_interval == 0:\n",
        "            \n",
        "            print(\n",
        "                \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\"\n",
        "                % (epoch, opt.n_epochs, i, len(dataloader), d_loss.item(), g_loss.item())\n",
        "            )\n",
        "            \n",
        "            save_image(gen_imgs.data[:25], \"images/%d.png\" % batches_done, nrow=5, normalize=True)\n",
        "            \n",
        "            fig, ax = plt.subplots(1, 10, figsize=(20, 2))\n",
        "            \n",
        "            for b in range(10):\n",
        "                \n",
        "                ax[b].imshow(gen_imgs.data[b].detach().cpu().numpy().squeeze())\n",
        "                ax[b].set_yticks([])\n",
        "                ax[b].set_xticks([])\n",
        "            \n",
        "            plt.show()\n",
        "            \n",
        "            gen_imgs.data[:25]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6O97M_F4xcl",
        "colab_type": "text"
      },
      "source": [
        "# Pix2Pix\n",
        "\n",
        "![Pix2Pix D and G](https://camo.githubusercontent.com/e8c023b62678aa244f1a474bf643c66c45ef0feb/687474703a2f2f6572696b6c696e6465726e6f72656e2e73652f696d616765732f706978327069785f6172636869746563747572652e706e67)\n",
        "\n",
        "![Pix2Pix Examples](https://github.com/eriklindernoren/PyTorch-GAN/raw/master/assets/pix2pix.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLG34bGvH6Ev",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/PyTorch-GAN/\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "%cd data/\n",
        "!bash download_pix2pix_dataset.sh facades > out.log\n",
        "%cd /content/PyTorch-GAN/implementations/pix2pix/\n",
        "\n",
        "import argparse\n",
        "import os\n",
        "import numpy as np\n",
        "import math\n",
        "import itertools\n",
        "import time\n",
        "import datetime\n",
        "import sys\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from models import *\n",
        "from datasets import *\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "class Opt:\n",
        "    epoch = 1\n",
        "    n_epochs = 20\n",
        "    dataset_name = 'facades'\n",
        "    batch_size = 1\n",
        "    lr = 0.0002\n",
        "    b1 = 0.5\n",
        "    b2 = 0.999\n",
        "    decay_epoch = 100\n",
        "    n_cpu = 4\n",
        "    img_height = 256\n",
        "    img_width = 256\n",
        "    channels = 3\n",
        "    sample_interval = 100\n",
        "    checkpoint_interval = -1\n",
        "\n",
        "opt = Opt()\n",
        "\n",
        "print(opt)\n",
        "\n",
        "os.makedirs(\"images/%s\" % opt.dataset_name, exist_ok=True)\n",
        "os.makedirs(\"saved_models/%s\" % opt.dataset_name, exist_ok=True)\n",
        "\n",
        "cuda = True if torch.cuda.is_available() else False\n",
        "\n",
        "# Loss functions\n",
        "criterion_GAN = torch.nn.MSELoss()\n",
        "criterion_pixelwise = torch.nn.L1Loss()\n",
        "\n",
        "# Loss weight of L1 pixel-wise loss between translated image and real image\n",
        "lambda_pixel = 100\n",
        "\n",
        "# Calculate output of image discriminator (PatchGAN)\n",
        "patch = (1, opt.img_height // 2 ** 4, opt.img_width // 2 ** 4)\n",
        "\n",
        "# Initialize generator and discriminator\n",
        "generator = GeneratorUNet()\n",
        "discriminator = Discriminator()\n",
        "\n",
        "if cuda:\n",
        "    generator = generator.cuda()\n",
        "    discriminator = discriminator.cuda()\n",
        "    criterion_GAN.cuda()\n",
        "    criterion_pixelwise.cuda()\n",
        "\n",
        "if opt.epoch != 1:\n",
        "    # Load pretrained models\n",
        "    generator.load_state_dict(torch.load(\"saved_models/%s/generator_%d.pth\" % (opt.dataset_name, opt.epoch)))\n",
        "    discriminator.load_state_dict(torch.load(\"saved_models/%s/discriminator_%d.pth\" % (opt.dataset_name, opt.epoch)))\n",
        "else:\n",
        "    # Initialize weights\n",
        "    generator.apply(models.weights_init_normal)\n",
        "    discriminator.apply(models.weights_init_normal)\n",
        "\n",
        "# Optimizers\n",
        "optimizer_G = torch.optim.Adam(generator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
        "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
        "\n",
        "# Configure dataloaders\n",
        "transforms_ = [\n",
        "    transforms.Resize((opt.img_height, opt.img_width), Image.BICUBIC),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "]\n",
        "\n",
        "dataloader = DataLoader(\n",
        "    ImageDataset(\"../../data/%s\" % opt.dataset_name, transforms_=transforms_),\n",
        "    batch_size=opt.batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=opt.n_cpu,\n",
        ")\n",
        "\n",
        "val_dataloader = DataLoader(\n",
        "    ImageDataset(\"../../data/%s\" % opt.dataset_name, transforms_=transforms_, mode=\"val\"),\n",
        "    batch_size=10,\n",
        "    shuffle=True,\n",
        "    num_workers=1,\n",
        ")\n",
        "\n",
        "# Tensor type\n",
        "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
        "\n",
        "\n",
        "def sample_images(batches_done):\n",
        "\n",
        "    \"\"\"Saves a generated sample from the validation set\"\"\"\n",
        "    imgs = next(iter(val_dataloader))\n",
        "    real_A = Variable(imgs[\"B\"].type(Tensor))\n",
        "    real_B = Variable(imgs[\"A\"].type(Tensor))\n",
        "    fake_B = generator(real_A)\n",
        "    img_sample = torch.cat((real_A.data, fake_B.data, real_B.data), -2)\n",
        "    save_image(img_sample, \"images/%s/%s.png\" % (opt.dataset_name, batches_done), nrow=5, normalize=True)\n",
        "    \n",
        "    fig, ax = plt.subplots(min(real_A.size(0), 2), 3, figsize=(12, 8))\n",
        "    \n",
        "    for i in range(min(real_A.size(0), 2)):\n",
        "    \n",
        "        ax[i, 0].imshow(real_A.data[i].cpu().numpy().transpose(1, 2, 0) * 0.5 + 0.5)\n",
        "        ax[i, 0].set_yticks([])\n",
        "        ax[i, 0].set_xticks([])\n",
        "        ax[i, 0].set_title('Real [A]')\n",
        "        \n",
        "        ax[i, 1].imshow(fake_B.data[i].cpu().numpy().transpose(1, 2, 0) * 0.5 + 0.5)\n",
        "        ax[i, 1].set_yticks([])\n",
        "        ax[i, 1].set_xticks([])\n",
        "        ax[i, 1].set_title('Fake [B]')\n",
        "        \n",
        "        ax[i, 2].imshow(real_B.data[i].cpu().numpy().transpose(1, 2, 0) * 0.5 + 0.5)\n",
        "        ax[i, 2].set_yticks([])\n",
        "        ax[i, 2].set_xticks([])\n",
        "        ax[i, 2].set_title('Real [B]')\n",
        "    \n",
        "    plt.show()\n",
        "\n",
        "\n",
        "################################################################################\n",
        "#  Training ####################################################################\n",
        "################################################################################\n",
        "\n",
        "prev_time = time.time()\n",
        "\n",
        "for epoch in range(opt.epoch, opt.n_epochs + 1):\n",
        "    \n",
        "    for i, batch in enumerate(dataloader):\n",
        "\n",
        "        # Model inputs\n",
        "        real_A = Variable(batch[\"B\"].type(Tensor))\n",
        "        real_B = Variable(batch[\"A\"].type(Tensor))\n",
        "\n",
        "        # Adversarial ground truths\n",
        "        valid = Variable(Tensor(np.ones((real_A.size(0), *patch))), requires_grad=False)\n",
        "        fake = Variable(Tensor(np.zeros((real_A.size(0), *patch))), requires_grad=False)\n",
        "\n",
        "        # ------------------\n",
        "        #  Train Generators\n",
        "        # ------------------\n",
        "\n",
        "        # TO DO: Clearing gradients for G optimizer.\n",
        "        optimizer_G.zero_grad()\n",
        "\n",
        "        # TO DO: GAN loss.\n",
        "        fake_B = generator(real_A)\n",
        "        pred_fake = discriminator(fake_B, real_A)\n",
        "        loss_GAN = criterion_GAN(pred_fake, valid)\n",
        "        \n",
        "        # TO DO: Pixel-wise loss\n",
        "        loss_pixel = criterion_pixelwise(fake_B, real_B)\n",
        "\n",
        "        # TO DO: Total loss\n",
        "        loss_G = loss_GAN + lambda_pixel * loss_pixel\n",
        "\n",
        "        # TO DO: G backward and optimizer step.\n",
        "        loss_G.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "        # ---------------------\n",
        "        #  Train Discriminator\n",
        "        # ---------------------\n",
        "\n",
        "        # TO DO: Clearing gradients for D optimizer.\n",
        "        optimizer_D.zero_grad()\n",
        "\n",
        "        # TO DO: Real loss\n",
        "        pred_real = discriminator(real_B, real_A)\n",
        "        loss_real = criterion_GAN(pred_real, valid)\n",
        "\n",
        "        # TO DO: Fake loss\n",
        "        pred_fake = discriminator(fake_B.detach(), real_A)\n",
        "        loss_fake = criterion_GAN(pred_fake, fake)\n",
        "\n",
        "        # TO DO: Total loss\n",
        "        loss_D = 0.5 * (loss_real + loss_fake)\n",
        "\n",
        "        # TO DO: D backward and optimizer step.\n",
        "        loss_D.backward()\n",
        "        optimizer_D.step()\n",
        "\n",
        "        # --------------\n",
        "        #  Log Progress\n",
        "        # --------------\n",
        "\n",
        "        # Determine approximate time left\n",
        "        batches_done = epoch * len(dataloader) + i\n",
        "        batches_left = opt.n_epochs * len(dataloader) - batches_done\n",
        "        time_left = datetime.timedelta(seconds=batches_left * (time.time() - prev_time))\n",
        "        prev_time = time.time()\n",
        "\n",
        "        # If at sample interval save image\n",
        "        if batches_done % opt.sample_interval == 0:\n",
        "\n",
        "            # Print log\n",
        "            sys.stdout.write(\n",
        "                '[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f, pixel: %f, adv: %f] ETA: %s'\n",
        "                % (\n",
        "                    epoch,\n",
        "                    opt.n_epochs,\n",
        "                    i,\n",
        "                    len(dataloader),\n",
        "                    loss_D.item(),\n",
        "                    loss_G.item(),\n",
        "                    loss_pixel.item(),\n",
        "                    loss_GAN.item(),\n",
        "                    time_left,\n",
        "                )\n",
        "            )\n",
        "            \n",
        "            sample_images(batches_done)\n",
        "\n",
        "    if opt.checkpoint_interval != -1 and epoch % opt.checkpoint_interval == 0:\n",
        "        \n",
        "        # Save model checkpoints\n",
        "        torch.save(generator.state_dict(), \"saved_models/%s/generator_%d.pth\" % (opt.dataset_name, epoch))\n",
        "        torch.save(discriminator.state_dict(), \"saved_models/%s/discriminator_%d.pth\" % (opt.dataset_name, epoch))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZR9hbZqnggkm",
        "colab_type": "text"
      },
      "source": [
        "# MUNIT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K38HrPd66IPA",
        "colab_type": "text"
      },
      "source": [
        "![MUNIT Architecture](https://www.dropbox.com/s/rw6f7trhwtvwq6x/MUNIT_Architecture.png?dl=1)\n",
        "\n",
        "![MUNIT Examples](https://github.com/eriklindernoren/PyTorch-GAN/raw/master/assets/munit.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ERf7haJ2CxR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/PyTorch-GAN/\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "%cd data/\n",
        "!bash download_pix2pix_dataset.sh edges2shoes > out.log\n",
        "%cd /content/PyTorch-GAN/implementations/munit/\n",
        "\n",
        "import argparse\n",
        "import os\n",
        "import numpy as np\n",
        "import math\n",
        "import itertools\n",
        "import datetime\n",
        "import time\n",
        "import sys\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import models\n",
        "from datasets import *\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "class Opt:\n",
        "    epoch = 1\n",
        "    n_epochs = 50\n",
        "    dataset_name = 'edges2shoes'\n",
        "    batch_size = 1\n",
        "    lr = 0.0001\n",
        "    b1 = 0.5\n",
        "    b2 = 0.999\n",
        "    decay_epoch = 100\n",
        "    n_cpu = 4\n",
        "    img_height = 128\n",
        "    img_width = 128\n",
        "    channels = 3\n",
        "    sample_interval = 2000\n",
        "    checkpoint_interval = -1\n",
        "    n_downsample = 2\n",
        "    n_residual = 2\n",
        "    dim = 32\n",
        "    style_dim = 8\n",
        "\n",
        "opt = Opt()\n",
        "\n",
        "cuda = torch.cuda.is_available()\n",
        "\n",
        "# Create sample and checkpoint directories\n",
        "os.makedirs(\"images/%s\" % opt.dataset_name, exist_ok=True)\n",
        "os.makedirs(\"saved_models/%s\" % opt.dataset_name, exist_ok=True)\n",
        "\n",
        "criterion_recon = torch.nn.L1Loss()\n",
        "\n",
        "# Initialize encoders, generators and discriminators\n",
        "Enc1 = models.Encoder(dim=opt.dim, n_downsample=opt.n_downsample, n_residual=opt.n_residual, style_dim=opt.style_dim)\n",
        "Dec1 = models.Decoder(dim=opt.dim, n_upsample=opt.n_downsample, n_residual=opt.n_residual, style_dim=opt.style_dim)\n",
        "Enc2 = models.Encoder(dim=opt.dim, n_downsample=opt.n_downsample, n_residual=opt.n_residual, style_dim=opt.style_dim)\n",
        "Dec2 = models.Decoder(dim=opt.dim, n_upsample=opt.n_downsample, n_residual=opt.n_residual, style_dim=opt.style_dim)\n",
        "D1 = models.MultiDiscriminator()\n",
        "D2 = models.MultiDiscriminator()\n",
        "\n",
        "if cuda:\n",
        "    Enc1 = Enc1.cuda()\n",
        "    Dec1 = Dec1.cuda()\n",
        "    Enc2 = Enc2.cuda()\n",
        "    Dec2 = Dec2.cuda()\n",
        "    D1 = D1.cuda()\n",
        "    D2 = D2.cuda()\n",
        "    criterion_recon.cuda()\n",
        "\n",
        "if opt.epoch != 1:\n",
        "    # Load pretrained models\n",
        "    Enc1.load_state_dict(torch.load(\"saved_models/%s/Enc1_%d.pth\" % (opt.dataset_name, opt.epoch)))\n",
        "    Dec1.load_state_dict(torch.load(\"saved_models/%s/Dec1_%d.pth\" % (opt.dataset_name, opt.epoch)))\n",
        "    Enc2.load_state_dict(torch.load(\"saved_models/%s/Enc2_%d.pth\" % (opt.dataset_name, opt.epoch)))\n",
        "    Dec2.load_state_dict(torch.load(\"saved_models/%s/Dec2_%d.pth\" % (opt.dataset_name, opt.epoch)))\n",
        "    D1.load_state_dict(torch.load(\"saved_models/%s/D1_%d.pth\" % (opt.dataset_name, opt.epoch)))\n",
        "    D2.load_state_dict(torch.load(\"saved_models/%s/D2_%d.pth\" % (opt.dataset_name, opt.epoch)))\n",
        "else:\n",
        "    # Initialize weights\n",
        "    Enc1.apply(models.weights_init_normal)\n",
        "    Dec1.apply(models.weights_init_normal)\n",
        "    Enc2.apply(models.weights_init_normal)\n",
        "    Dec2.apply(models.weights_init_normal)\n",
        "    D1.apply(models.weights_init_normal)\n",
        "    D2.apply(models.weights_init_normal)\n",
        "\n",
        "# Loss weights\n",
        "lambda_gan = 1\n",
        "lambda_id = 10\n",
        "lambda_style = 1\n",
        "lambda_cont = 1\n",
        "lambda_cyc = 0\n",
        "\n",
        "# Optimizers\n",
        "optimizer_G = torch.optim.Adam(\n",
        "    itertools.chain(Enc1.parameters(), Dec1.parameters(), Enc2.parameters(), Dec2.parameters()),\n",
        "    lr=opt.lr,\n",
        "    betas=(opt.b1, opt.b2),\n",
        ")\n",
        "optimizer_D1 = torch.optim.Adam(D1.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
        "optimizer_D2 = torch.optim.Adam(D2.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
        "\n",
        "# Learning rate update schedulers\n",
        "lr_scheduler_G = torch.optim.lr_scheduler.StepLR(\n",
        "    optimizer_G, step_size=20, gamma=0.5)\n",
        "lr_scheduler_D1 = torch.optim.lr_scheduler.StepLR(\n",
        "    optimizer_D1, step_size=20, gamma=0.5)\n",
        "lr_scheduler_D2 = torch.optim.lr_scheduler.StepLR(\n",
        "    optimizer_D2, step_size=20, gamma=0.5)\n",
        "\n",
        "Tensor = torch.cuda.FloatTensor if cuda else torch.Tensor\n",
        "\n",
        "# Configure dataloaders\n",
        "transforms_ = [\n",
        "    transforms.Resize((opt.img_height, opt.img_width), Image.BICUBIC),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "]\n",
        "\n",
        "dataloader = DataLoader(\n",
        "    ImageDataset(\"../../data/%s\" % opt.dataset_name, transforms_=transforms_),\n",
        "    batch_size=opt.batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=opt.n_cpu,\n",
        ")\n",
        "\n",
        "val_dataloader = DataLoader(\n",
        "    ImageDataset(\"../../data/%s\" % opt.dataset_name, transforms_=transforms_, mode=\"val\"),\n",
        "    batch_size=5,\n",
        "    shuffle=True,\n",
        "    num_workers=1,\n",
        ")\n",
        "\n",
        "\n",
        "def sample_images(batches_done):\n",
        "    \"\"\"Saves a generated sample from the validation set\"\"\"\n",
        "    imgs = next(iter(val_dataloader))\n",
        "    img_samples = None\n",
        "    for i, (img1, img2) in enumerate(zip(imgs[\"A\"], imgs[\"B\"])):\n",
        "        # Create copies of image\n",
        "        X1 = img1.unsqueeze(0).repeat(opt.style_dim, 1, 1, 1)\n",
        "        X1 = Variable(X1.type(Tensor))\n",
        "        # Get random style codes\n",
        "        s_code = np.random.uniform(-1, 1, (opt.style_dim, opt.style_dim))\n",
        "        s_code = Variable(Tensor(s_code))\n",
        "        # Generate samples\n",
        "        c_code_1, _ = Enc1(X1)\n",
        "        X12 = Dec2(c_code_1, s_code)\n",
        "        # Concatenate samples horisontally\n",
        "        X12 = torch.cat([x for x in X12.data.cpu()], -1)\n",
        "        img_sample = torch.cat((img1, X12), -1).unsqueeze(0)\n",
        "        # Concatenate with previous samples vertically\n",
        "        img_samples = img_sample if img_samples is None else torch.cat((img_samples, img_sample), -2)\n",
        "    save_image(img_samples, \"images/%s/%s.png\" % (opt.dataset_name, batches_done), nrow=5, normalize=True)\n",
        "    \n",
        "    print(img_samples.size())\n",
        "    \n",
        "    fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
        "    \n",
        "    ax.imshow(img_samples.data[0].cpu().numpy().transpose(1, 2, 0) * 0.5 + 0.5)\n",
        "    ax.set_yticks([])\n",
        "    ax.set_xticks([])    \n",
        "    \n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# ----------\n",
        "#  Training\n",
        "# ----------\n",
        "\n",
        "# Adversarial ground truths\n",
        "valid = 1\n",
        "fake = 0\n",
        "\n",
        "prev_time = time.time()\n",
        "\n",
        "for epoch in range(opt.epoch, opt.n_epochs):\n",
        "\n",
        "    for i, batch in enumerate(dataloader):\n",
        "\n",
        "        # Set model input\n",
        "        X1 = Variable(batch[\"A\"].type(Tensor))\n",
        "        X2 = Variable(batch[\"B\"].type(Tensor))\n",
        "\n",
        "        # Sampled style codes\n",
        "        style_1 = Variable(torch.randn(X1.size(0), opt.style_dim, 1, 1).type(Tensor))\n",
        "        style_2 = Variable(torch.randn(X1.size(0), opt.style_dim, 1, 1).type(Tensor))\n",
        "\n",
        "        # -------------------------------\n",
        "        #  Train Encoders and Generators\n",
        "        # -------------------------------\n",
        "\n",
        "        optimizer_G.zero_grad()\n",
        "\n",
        "        # Get shared latent representation\n",
        "        c_code_1, s_code_1 = Enc1(X1)\n",
        "        c_code_2, s_code_2 = Enc2(X2)\n",
        "\n",
        "        # Reconstruct images\n",
        "        X11 = Dec1(c_code_1, s_code_1)\n",
        "        X22 = Dec2(c_code_2, s_code_2)\n",
        "\n",
        "        # Translate images\n",
        "        X21 = Dec1(c_code_2, style_1)\n",
        "        X12 = Dec2(c_code_1, style_2)\n",
        "\n",
        "        # Cycle translation\n",
        "        c_code_21, s_code_21 = Enc1(X21)\n",
        "        c_code_12, s_code_12 = Enc2(X12)\n",
        "        X121 = Dec1(c_code_12, s_code_1) if lambda_cyc > 0 else 0\n",
        "        X212 = Dec2(c_code_21, s_code_2) if lambda_cyc > 0 else 0\n",
        "\n",
        "        # Losses\n",
        "        loss_GAN_1 = lambda_gan * D1.compute_loss(X21, valid)\n",
        "        loss_GAN_2 = lambda_gan * D2.compute_loss(X12, valid)\n",
        "        loss_ID_1 = lambda_id * criterion_recon(X11, X1)\n",
        "        loss_ID_2 = lambda_id * criterion_recon(X22, X2)\n",
        "        loss_s_1 = lambda_style * criterion_recon(s_code_21, style_1)\n",
        "        loss_s_2 = lambda_style * criterion_recon(s_code_12, style_2)\n",
        "        loss_c_1 = lambda_cont * criterion_recon(c_code_12, c_code_1.detach())\n",
        "        loss_c_2 = lambda_cont * criterion_recon(c_code_21, c_code_2.detach())\n",
        "        loss_cyc_1 = lambda_cyc * criterion_recon(X121, X1) if lambda_cyc > 0 else 0\n",
        "        loss_cyc_2 = lambda_cyc * criterion_recon(X212, X2) if lambda_cyc > 0 else 0\n",
        "\n",
        "        # Total loss\n",
        "        loss_G = (\n",
        "            loss_GAN_1\n",
        "            + loss_GAN_2\n",
        "            + loss_ID_1\n",
        "            + loss_ID_2\n",
        "            + loss_s_1\n",
        "            + loss_s_2\n",
        "            + loss_c_1\n",
        "            + loss_c_2\n",
        "            + loss_cyc_1\n",
        "            + loss_cyc_2\n",
        "        )\n",
        "\n",
        "        loss_G.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "        # -----------------------\n",
        "        #  Train Discriminator 1\n",
        "        # -----------------------\n",
        "\n",
        "        optimizer_D1.zero_grad()\n",
        "\n",
        "        loss_D1 = D1.compute_loss(X1, valid) + D1.compute_loss(X21.detach(), fake)\n",
        "\n",
        "        loss_D1.backward()\n",
        "        optimizer_D1.step()\n",
        "\n",
        "        # -----------------------\n",
        "        #  Train Discriminator 2\n",
        "        # -----------------------\n",
        "\n",
        "        optimizer_D2.zero_grad()\n",
        "\n",
        "        loss_D2 = D2.compute_loss(X2, valid) + D2.compute_loss(X12.detach(), fake)\n",
        "\n",
        "        loss_D2.backward()\n",
        "        optimizer_D2.step()\n",
        "\n",
        "        # --------------\n",
        "        #  Log Progress\n",
        "        # --------------\n",
        "\n",
        "        # Determine approximate time left\n",
        "        batches_done = epoch * len(dataloader) + i\n",
        "        batches_left = opt.n_epochs * len(dataloader) - batches_done\n",
        "        time_left = datetime.timedelta(seconds=batches_left * (time.time() - prev_time))\n",
        "        prev_time = time.time()\n",
        "\n",
        "        # Print log\n",
        "        sys.stdout.write(\n",
        "            \"\\r[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f] ETA: %s\"\n",
        "            % (epoch, opt.n_epochs, i, len(dataloader), (loss_D1 + loss_D2).item(), loss_G.item(), time_left)\n",
        "        )\n",
        "\n",
        "        # If at sample interval save image\n",
        "        if batches_done % opt.sample_interval == 0:\n",
        "            sample_images(batches_done)\n",
        "\n",
        "    # Update learning rates\n",
        "    lr_scheduler_G.step()\n",
        "    lr_scheduler_D1.step()\n",
        "    lr_scheduler_D2.step()\n",
        "\n",
        "    if opt.checkpoint_interval != -1 and epoch % opt.checkpoint_interval == 0:\n",
        "        # Save model checkpoints\n",
        "        torch.save(Enc1.state_dict(), \"saved_models/%s/Enc1_%d.pth\" % (opt.dataset_name, epoch))\n",
        "        torch.save(Dec1.state_dict(), \"saved_models/%s/Dec1_%d.pth\" % (opt.dataset_name, epoch))\n",
        "        torch.save(Enc2.state_dict(), \"saved_models/%s/Enc2_%d.pth\" % (opt.dataset_name, epoch))\n",
        "        torch.save(Dec2.state_dict(), \"saved_models/%s/Dec2_%d.pth\" % (opt.dataset_name, epoch))\n",
        "        torch.save(D1.state_dict(), \"saved_models/%s/D1_%d.pth\" % (opt.dataset_name, epoch))\n",
        "        torch.save(D2.state_dict(), \"saved_models/%s/D2_%d.pth\" % (opt.dataset_name, epoch))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
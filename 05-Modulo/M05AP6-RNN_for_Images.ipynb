{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "S06A04 - RNN for Images.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XT2KT5vRIKmE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Basic imports.\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import time\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils import data\n",
        "from torch.backends import cudnn\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from torchvision import models\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "\n",
        "from skimage import io\n",
        "\n",
        "from sklearn import metrics\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "cudnn.benchmark = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoQdWCc-ITgt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Setting predefined arguments.\n",
        "args = {\n",
        "    'epoch_num': 50,      # Number of epochs.\n",
        "    'n_classes': 10,      # Number of classes.\n",
        "    'lr': 1e-3,           # Learning rate.\n",
        "    'weight_decay': 5e-4, # L2 penalty.\n",
        "    'momentum': 0.9,      # Momentum.\n",
        "    'num_workers': 3,     # Number of workers on data loader.\n",
        "    'batch_size': 30,     # Mini-batch size.\n",
        "    'visibility': 0.75\n",
        "}\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    args['device'] = torch.device('cuda')\n",
        "else:\n",
        "    args['device'] = torch.device('cpu')\n",
        "\n",
        "print(args['device'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNejlgPiIFqr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "root = './'\n",
        "\n",
        "# Setting dataloader.\n",
        "data_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "train_set = datasets.MNIST(root,\n",
        "                             train=True,\n",
        "                             download=True,\n",
        "                             transform=data_transform)\n",
        "test_set = datasets.MNIST(root,\n",
        "                            train=False,\n",
        "                            download=False,\n",
        "                            transform=data_transform)\n",
        "\n",
        "train_loader = DataLoader(train_set,\n",
        "                          args['batch_size'],\n",
        "                          num_workers=args['num_workers'],\n",
        "                          shuffle=True)\n",
        "test_loader = DataLoader(test_set,\n",
        "                         args['batch_size'],\n",
        "                         num_workers=args['num_workers'],\n",
        "                         shuffle=False)\n",
        "\n",
        "print('Size of training set: ' + str(len(train_set)) + ' samples')\n",
        "print('Size of test set: ' + str(len(test_set)) + ' samples')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_vTRRZNWMFL",
        "colab_type": "text"
      },
      "source": [
        "# Atividade Prática\n",
        "\n",
        "## Classificação MNIST\n",
        "\n",
        "Implemente um modelo recorrente capaz de realizar classificação de imagens. Considere as imagens do MNIST, de dimensionalidade $28 \\times 28$. Para criar um modelo de sequência poderíamos por exemplo criar uma sequência de $784$ elementos (pixels), ou poderíamos fazer a correlação de múltiplos recortes da imagem. \n",
        "\n",
        "A figura a seguir apresenta uma proposta de modelo recorrente para que você implemente e otimize para classificação de dígitos. Por se tratar de um dataset conhecido, e uma arquitetura conhecida, a atividade de hoje não trará instruções. Sinta-se livre para construir a rede proposta a seguir, ou variações dela. \n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1fQcVWO3FzQ7m6iFmsnbmHe42bqCZi4S2)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-9Aol-vIUcK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO Crie rede recorrente de classificação\n",
        "\n",
        "# Aproveite para ter uma noção da quantidade de parâmetros de modelos desse porte.\n",
        "model_parameters = filter(lambda p: p.requires_grad, model_rnn.parameters())\n",
        "params = sum([np.prod(p.size()) for p in model_parameters])\n",
        "print('Total de %d parametros'%params)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1WyQ7I_MP9Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set otimizador e função de custo"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQlnKpQyNjQX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(train_loader, net, criterion, optimizer, epoch):\n",
        "\n",
        "    # Setting network for training mode.\n",
        "    net.train()\n",
        "\n",
        "    # Lists for losses and metrics.\n",
        "    train_loss = []\n",
        "    \n",
        "    begin = time.time()\n",
        "    \n",
        "    # Iterating over batches.\n",
        "    for i, batch_data in enumerate(train_loader):\n",
        "\n",
        "        # TODO iterate over batch\n",
        "       \n",
        "        \n",
        "        # Updating lists.\n",
        "        train_loss.append(loss.data.item())\n",
        "    \n",
        "    end = time.time()\n",
        "    \n",
        "    train_loss = np.asarray(train_loss)\n",
        "    \n",
        "    # Printing training epoch loss and metrics.\n",
        "    print('--------------------------------------------------------------------')\n",
        "    print('[epoch %d], [train loss %.4f +/- %.4f | Time: %.2f ]' % (\n",
        "        epoch, train_loss.mean(), train_loss.std(), end-begin))\n",
        "    print('--------------------------------------------------------------------')\n",
        "        \n",
        "    return train_loss.mean(), end-begin\n",
        "    \n",
        "    \n",
        "def test(test_loader, net, criterion, epoch):\n",
        "\n",
        "    # Setting network for evaluation mode.\n",
        "    net.eval()\n",
        "\n",
        "    # Lists for losses and metrics.\n",
        "    test_loss = []\n",
        "    prd_list = []\n",
        "    lab_list = []\n",
        "    \n",
        "    begin = time.time()\n",
        "    \n",
        "    # Iterating over batches.\n",
        "    for i, batch_data in enumerate(train_loader):\n",
        "\n",
        "        # TODO iterate over batch\n",
        "        \n",
        "        # Obtaining predictions.\n",
        "        prds = outs.data.max(dim=1)[1].cpu().numpy()\n",
        "        \n",
        "        # Updating lists.\n",
        "        test_loss.append(loss.data.item())\n",
        "        prd_list.append(prds)\n",
        "        lab_list.append(labs.detach().cpu().numpy())\n",
        "    \n",
        "    end = time.time()\n",
        "    \n",
        "    # Computing accuracy.\n",
        "    acc = metrics.accuracy_score(np.asarray(lab_list).ravel(),\n",
        "                                 np.asarray(prd_list).ravel())\n",
        "    \n",
        "    test_loss = np.asarray(test_loss)\n",
        "    \n",
        "    # Printing training epoch loss and metrics.\n",
        "    print('--------------------------------------------------------------------')\n",
        "    print('[epoch %d], [test loss %.4f +/- %.4f | Time: %.2f], [acc %.4f]' % (\n",
        "        epoch, test_loss.mean(), test_loss.std(), end-begin, acc))\n",
        "    print('--------------------------------------------------------------------')\n",
        "    \n",
        "    return test_loss.mean(), end-begin, acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_I81ahONj9S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Iterating over epochs.\n",
        "for epoch in range(1, args['epoch_num'] + 1):\n",
        "\n",
        "    # Training function.\n",
        "    trloss, trtime = train(train_loader, model_rnn, criterion, optimizer, epoch)\n",
        "\n",
        "    # Computing test loss and metrics.\n",
        "    tsloss, tstime, tsacc = test(test_loader, model_rnn, criterion, epoch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkkCWk5LEYuM",
        "colab_type": "text"
      },
      "source": [
        "# Atividade Prática II\n",
        "\n",
        "## Pixel RNN\n",
        "\n",
        "Também é possível trabalhar de forma auto-supervisionada usando modelos recorrentes. Um exemplo de destaque é a PixelRNN, que considera cada pixel da imagem como uma unidade de sequência, e propõe um modelo probabilístico para prever o próximo pixel, dada uma sequência de pixels antecessores. A imagem a seguir ilustra essa proposta.\n",
        "* Paper: https://arxiv.org/abs/1601.06759\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=198yw7kilta27G_bx3Ldcjguor_-qkk97\" width=\"250\"><br><br>\n",
        "\n",
        "A melhor configuração dentre as propostas no artigo foi capaz de preencher lacunas em imagens com oclusões artificiais. Note que é preciso alimentar o modelo com uma porção significativa da imagem para que ele seja capaz de prever o restante.\n",
        "\n",
        "<img src=\"https://miro.medium.com/max/700/0*o7PUa9K5rPGeFIcx.\" width=\"600\"><br><br>\n",
        "\n",
        "\n",
        "\n",
        "Uma modelagem simples para esse problema, se parece com o que aprendemos na aula de geração de sequências (seq2seq), porém não existe a etapa de codificação, apenas a decodificação do valor seguinte a partir do valor atual. O objetivo aqui é realizar uma **regressão** do valor de cada pixel no intervalo ```(0, 1)```.\n",
        "\n",
        "* Entrada: vetor linearizado e com a oclusão artificial ```(batch_size, 784, 1)```. A oclusão ocorre através do preenchimento com zeros em uma região fixa da imagem. O parâmetro ```args['visibility']``` determina o percentual da imagem visível para a rede.\n",
        "* Saída esperada: dígito reconstruído extrapolando a oclusão. Para isso, o cálculo da loss é realizado comparando a reconstrução com o dado **original**. ```(batch_size, 784, 1)```\n",
        "\n",
        "Nota: Para essa aplicação não faremos distinção entre o forward de treinamento e de inferência. \n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1DzHtZXT1dsWm4s7xbZfmu0NiLmKw7jpL)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2i0JrYNfpFX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO Crie e instancie nossa PixelRNN versão pocket."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZG69bouPpt9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO set otimização e loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWEsHueEiO_k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(train_loader, net, criterion, optimizer, epoch):\n",
        "\n",
        "    # Setting network for training mode.\n",
        "    net.train()\n",
        "\n",
        "    # Lists for losses and metrics.\n",
        "    train_loss = []\n",
        "    \n",
        "    begin = time.time()\n",
        "    \n",
        "    # Iterating over batches.\n",
        "    for i, batch_data in enumerate(train_loader):\n",
        "        if i > 501: break  \n",
        "\n",
        "        # Obtaining images, labels and paths for batch.\n",
        "        inps, _ = batch_data\n",
        "        labs = inps.view(inps.size(0),-1).unsqueeze(-1)\n",
        "        \n",
        "        \n",
        "        # Casting to cuda variables.\n",
        "        inps = inps.to(args['device'])\n",
        "        labs = labs.to(args['device'])\n",
        "        \n",
        "        patch_occ = int(args['visibility'] * 784) \n",
        "        input_occ = torch.zeros(labs.size()).to(args['device'])\n",
        "        input_occ[:,:patch_occ] = labs[:, :patch_occ]\n",
        "        \n",
        "        # Clears the gradients of optimizer.\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forwarding.\n",
        "        outs = net(input_occ[:,:-1])\n",
        "\n",
        "        # Computing loss.\n",
        "        loss = 0.\n",
        "        for k, out in enumerate(outs):\n",
        "          loss += criterion(out, labs[k, 1:])\n",
        "        \n",
        "        # Computing backpropagation.\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        # Plot prediction\n",
        "        prds = np.append(np.zeros( (len(outs),1,1) ), outs.detach().data.cpu().numpy(), axis=1)\n",
        "        if i % 250 == 1:\n",
        "          print(loss)\n",
        "          fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(10,5))\n",
        "          \n",
        "          img_label = labs[0].detach().data.cpu().numpy().reshape(inps.size(2), inps.size(3))\n",
        "          axs[0].imshow(img_label)\n",
        "          axs[0].set_title('Ground Truth')\n",
        "          \n",
        "          img_label = input_occ[0].detach().data.cpu().numpy().reshape(inps.size(2), inps.size(3))\n",
        "          axs[1].imshow(img_label)\n",
        "          axs[1].set_title('Input (Occlusion)')\n",
        "          \n",
        "          img = prds.reshape(inps.size(0), inps.size(2), inps.size(3))[0]\n",
        "          axs[2].imshow(img)\n",
        "          axs[2].set_title('Prediction')\n",
        "          \n",
        "          plt.show()\n",
        "          plt.close(fig)\n",
        "          \n",
        "        \n",
        "        # Updating lists.\n",
        "        train_loss.append(loss.data.item())\n",
        "    \n",
        "    end = time.time()\n",
        "    \n",
        "    train_loss = np.asarray(train_loss)\n",
        "    \n",
        "    # Printing training epoch loss and metrics.\n",
        "    print('--------------------------------------------------------------------')\n",
        "    print('[epoch %d], [train loss %.4f +/- %.4f | Time: %.2f ]' % (\n",
        "        epoch, train_loss.mean(), train_loss.std(), end-begin))\n",
        "    print('--------------------------------------------------------------------')\n",
        "        \n",
        "    return train_loss.mean(), end-begin\n",
        "    \n",
        "    \n",
        "def test(test_loader, net, criterion, epoch):\n",
        "\n",
        "    # Setting network for evaluation mode.\n",
        "    net.eval()\n",
        "\n",
        "    # Lists for losses and metrics.\n",
        "    test_loss = []\n",
        "    prd_list = []\n",
        "    lab_list = []\n",
        "    \n",
        "    begin = time.time()\n",
        "    \n",
        "    # Iterating over batches.\n",
        "    for i, batch_data in enumerate(train_loader):\n",
        "        if i > 401: break\n",
        "\n",
        "        # Obtaining images, labels and paths for batch.\n",
        "        inps, _ = batch_data\n",
        "        labs = inps.view(inps.size(0),-1).unsqueeze(-1)\n",
        "\n",
        "        # Casting to cuda variables.\n",
        "        inps = inps.to(args['device'])\n",
        "        labs = labs.to(args['device'])\n",
        "        \n",
        "        patch_occ = int(args['visibility'] * 784) \n",
        "        input_occ = torch.zeros(labs.size()).to(args['device'])\n",
        "        input_occ[:,:patch_occ] = labs[:, :patch_occ]\n",
        "\n",
        "        # Forwarding.\n",
        "        outs = net(labs[:, :-1])\n",
        "\n",
        "        # Plot prediction\n",
        "        prds = np.append(np.zeros( (len(outs),1,1) ), outs.detach().data.cpu().numpy(), axis=1)\n",
        "        if i % 250 == 1:\n",
        "          print(loss)\n",
        "          fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(10,5))\n",
        "          \n",
        "          img_label = labs[0].detach().data.cpu().numpy().reshape(inps.size(2), inps.size(3))\n",
        "          axs[0].imshow(img_label)\n",
        "          axs[0].set_title('Ground Truth')\n",
        "          \n",
        "          img_label = input_occ[0].detach().data.cpu().numpy().reshape(inps.size(2), inps.size(3))\n",
        "          axs[1].imshow(img_label)\n",
        "          axs[1].set_title('Input (Occlusion)')\n",
        "          \n",
        "          img = prds.reshape(inps.size(0), inps.size(2), inps.size(3))[0]\n",
        "          axs[2].imshow(img)\n",
        "          axs[2].set_title('Prediction')\n",
        "          \n",
        "          plt.show()\n",
        "          plt.close(fig)\n",
        "        \n",
        "        # Computing loss.\n",
        "        loss = 0.\n",
        "        for k, out in enumerate(outs):\n",
        "          loss += criterion(out, labs[k, 1:])\n",
        "        \n",
        "        # Obtaining predictions.\n",
        "        prds = outs.data.max(dim=1)[1].cpu().numpy()\n",
        "        \n",
        "        # Updating lists.\n",
        "        test_loss.append(loss.data.item())\n",
        "        prd_list.append(prds)\n",
        "        lab_list.append(labs.detach().cpu().numpy())\n",
        "        \n",
        "    end = time.time()\n",
        "    \n",
        "    # Computing accuracy.\n",
        "    \n",
        "    test_loss = np.asarray(test_loss)\n",
        "    \n",
        "    # Printing training epoch loss and metrics.\n",
        "    print('--------------------------------------------------------------------')\n",
        "    print('[epoch %d], [test loss %.4f +/- %.4f | Time: %.2f]' % (\n",
        "        epoch, test_loss.mean(), test_loss.std(), end-begin))\n",
        "    print('--------------------------------------------------------------------')\n",
        "    \n",
        "    return test_loss.mean(), end-begin"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlbssN1AiuOu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Iterating over epochs.\n",
        "for epoch in range(1, args['epoch_num'] + 1):\n",
        "\n",
        "#     Training function.\n",
        "    train(train_loader, pixelrnn, criterion, optimizer, epoch)\n",
        "\n",
        "    # Computing test loss and metrics.\n",
        "    test(test_loader, pixelrnn, criterion, epoch)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
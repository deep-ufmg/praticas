{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "S05A02_2 - Análise de Sentimentos.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRmGzugay1zH",
        "colab_type": "text"
      },
      "source": [
        "# Preâmbulo\n",
        "\n",
        "Imports básicos\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_i1QxWp04tmc",
        "colab_type": "code",
        "outputId": "f8a0a5d3-7732-45b0-c303-a6520c752f41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Basic imports.\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils import data\n",
        "from torch.backends import cudnn\n",
        "\n",
        "from sklearn import metrics\n",
        "\n",
        "from torchtext import data\n",
        "from torchtext import datasets\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "cudnn.benchmark = True\n",
        "\n",
        "SEED = 1234\n",
        "torch.manual_seed(SEED)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f2470f5ff90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjxhn0iD4oA7",
        "colab_type": "code",
        "outputId": "340307a9-1753-4f04-d09b-8a00f0382ca7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Setting predefined arguments.\n",
        "args = {\n",
        "    'epoch_num': 5,       # Number of epochs.\n",
        "    'lr': 1e-3,           # Learning rate.\n",
        "    'weight_decay': 5e-4, # L2 penalty.\n",
        "    'momentum': 0.9,      # Momentum.\n",
        "    'num_workers': 6,     # Number of workers on data loader.\n",
        "    'batch_size': 10,     # Mini-batch size.\n",
        "    'clip_norm': 6.0,     # Upper limit on gradient L2 norm ###\n",
        "}\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    args['device'] = torch.device('cuda')\n",
        "else:\n",
        "    args['device'] = torch.device('cpu')\n",
        "\n",
        "print(args['device'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ij33hY1dzFJZ",
        "colab_type": "text"
      },
      "source": [
        "## IMDB Movie Reviews\n",
        "\n",
        "Dataset disponível no torchtext, contendo 50 mil amostras polarizadas de reviews de filmes no IMDB."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "c74ed124-4882-4979-9339-583e326e2537",
        "id": "9WPQXd0dSSuC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "TEXT = data.Field(tokenize = 'spacy', include_lengths = True)\n",
        "LABEL = data.LabelField(dtype = torch.float)\n",
        "\n",
        "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)\n",
        "train_data, valid_data = train_data.split(random_state = random.seed(SEED))\n",
        "\n",
        "MAX_VOCAB_SIZE = 25_000\n",
        "\n",
        "TEXT.build_vocab(train_data, \n",
        "                 max_size = MAX_VOCAB_SIZE, \n",
        "                 vectors = \"glove.6B.100d\", \n",
        "                 unk_init = torch.Tensor.normal_)\n",
        "\n",
        "LABEL.build_vocab(train_data)\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), \n",
        "    batch_size = args['batch_size'],\n",
        "    sort_within_batch = True,\n",
        "    device = args['device'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "downloading aclImdb_v1.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:07<00:00, 11.4MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mpb0yplpySL6",
        "colab_type": "code",
        "outputId": "fe0db0d3-34af-4332-cf9e-ff03a62da746",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "for sample in train_data:\n",
        "  print(sample.text)\n",
        "  print(sample.label)\n",
        "  break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Unbelievably', 'bad', 'acting', ',', 'a', 'no', 'good', ',', 'unclear', 'story', 'and', 'flashy', 'images', 'and', 'slow', '-', 'motions', 'where', 'they', 'are', 'needed', 'the', 'least', ':', 'Adrenaline', 'is', 'everything', 'a', 'movie', 'should', 'not', 'be.<br', '/><br', '/>Georgina', 'Verbaan', '(', 'a', 'so', '-', 'and', '-', 'so', 'dutch', 'soap', 'actress', 'who', 'has', \"n't\", 'attended', 'her', 'English', 'classes', ')', 'plays', 'rich', 'girl', 'Freya', ',', 'who', 'has', 'the', 'habit', 'of', \"'\", 'thrill', '-', 'seeking', \"'\", '.', 'Which', 'basicly', 'is', 'doing', 'dangerous', 'stunts', ',', 'break', 'stuff', 'and', 'annoy', 'people', '.', 'And', 'not', 'in', 'a', 'fun', 'Jackass', 'way', '.', 'Then', 'there', \"'s\", 'Dracko', '(', 'Rivas', ')', '.', 'He', 'kinda', 'leads', 'the', 'bunch', 'but', 'has', 'other', 'illegal', 'activities', 'on', 'the', 'side', '.', 'Then', 'there', \"'s\", 'Freya', \"'s\", 'dad', '(', 'Lockyer', ')', ',', 'who', 'plays', 'a', 'dubious', 'role', 'as', 'well', '.', 'And', ',', 'in', 'the', 'end', ',', 'we', 'got', 'Jason', '(', 'debutant', 'Fyall', ')', ',', 'the', 'boyfriend', 'of', 'Freya.<br', '/><br', '/>One', 'day', ',', 'Freya', 'gets', 'disappeared', 'and', 'everybody', 'seems', 'involved', 'but', 'we', ',', 'the', 'viewer', 'really', 'do', \"n't\", 'care', 'as', 'nobody', 'of', 'the', 'cast', 'is', 'either', 'likable', 'or', 'believable', ',', 'and', 'the', 'story', 'does', \"n't\", 'make', 'any', 'sense.<br', '/><br', '/>Why', 'was', 'this', 'even', 'made', '?', '2/10', '.']\n",
            "neg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnDMjbbhugxU",
        "colab_type": "text"
      },
      "source": [
        "# Atividade Prática\n",
        "\n",
        "A prática de hoje é inspirada na arquitetura proposta em: https://github.com/NVIDIA/sentiment-discovery\n",
        "*  A NVIDIA treinou um modelo de linguagem capaz de aprender a classificar sentimentos de forma não supervisionada\n",
        "*  Essa atividade é uma versão bastante reduzida da arquitetura e realiza treinamento supervisionado.\n",
        "\n",
        "O objetivo é treinar um modelo recorrente para classificar a emoção em um texto de forma binária (positiva e negativa). Essa área, e suas vertentes mais sofisticadas, recebem o nome de Análise de Sentimentos. Para isso, usaremos a arquitetura proposta na imagem a seguir, a qual agrega a informação acumulada em todos os timesteps. Se tratando de uma rede bidirecional, o hidden state produzido em todos os timesteps possui alto potencial discriminativo. \n",
        "\n",
        "Realizaremos a técnica do **Concat Pooling**, explorando a capacidade do pooling adaptativo de produzir uma saída de tamanho fixo independente do tamanho da entrada. Isso nos permite transformar as saídas de uma sequência de qualquer tamanho em uma única saída altamente informativa.\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1Rkzr_eIZb8-AditmY1TWga814oPxPvoA)\n",
        "\n",
        "## Init\n",
        "\n",
        "Mantivemos a nomenclatura de blocos utilizada na arquitetura de [Sentiment Discovery](https://github.com/NVIDIA/sentiment-discovery), apesar de no nosso serem blocos de camadas solitárias. É importante absorver a intuição de cada um desses blocos quando nos depararmos com modelos maiores.\n",
        "\n",
        "### Encoder\n",
        "Esse bloco é responsável por projetar as palavras da entrada em um espaço de maior semântica. O uso do dropout após uma camada de embedding impede que determinadas palavras dominem a classficação, evitando overfit.\n",
        "* Embedding\n",
        "* Dropout \n",
        "\n",
        "Lembre-se de carregar os pesos pré treinados do GloVe, como vimos no notebook anterior.\n",
        "\n",
        "### Featurizer\n",
        "Aqui construiremos as features recorrentes. Essa etapa inclui o pooling da média e da máxima na dimensão do tempo, porém sugerimos implementar na função do forward.\n",
        "* BiLSTM: 1 camada com 64 neurônios (modelos muito grandes vão demorar **muito** de treinar)\n",
        "\n",
        "### Classifier\n",
        "Uma vez construído o vetor de características recorrentes (a saída do concat pool), vamos alimentar uma camada densa para realizar a classificação. \n",
        "* Linear\n",
        "* Sigmoid\n",
        "\n",
        "**Atenção:** qual a dimensionalidade de entrada da camada densa?\n",
        "\n",
        "## Forward\n",
        "\n",
        "O único detalhe diferente do que estamos acostumados é a realização do concat pooling. Na transição entre o featurizer o classifier, utilize as funções a seguir para aplicar duas formas de **pooling na dimensão do tempo** nos hidden states. \n",
        "\n",
        "*  Adaptive Average Pooling https://pytorch.org/docs/stable/nn.html?highlight=adaptive#torch.nn.functional.adaptive_avg_pool1d\n",
        "*  Adaptive Max Pooling https://pytorch.org/docs/stable/nn.html?highlight=adaptive#torch.nn.functional.adaptive_max_pool1d\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPtfS-_OXV1m",
        "colab_type": "code",
        "outputId": "b4c9b57d-7a0a-4e58-96ae-a0392f08b185",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# TODO Implemente aqui o seu modelo"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BiLSTM(\n",
            "  (embedding): Embedding(25002, 100, padding_idx=1)\n",
            "  (dropout): Dropout(p=0.5)\n",
            "  (bilstm): LSTM(100, 64, bidirectional=True)\n",
            "  (linear): Linear(in_features=256, out_features=1, bias=True)\n",
            "  (activation): Sigmoid()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uK1YkalKXZ6n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO Setting optimizer.\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gxukr3BnW2oI",
        "colab_type": "text"
      },
      "source": [
        "**Loss de classificação binária**: BCE (Binary Cross Entropy)\n",
        "\n",
        "Documentação: https://pytorch.org/docs/stable/nn.html#torch.nn.BCELoss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3i7BVYPXfDC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO Setting loss.\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2Gr9zNOXg94",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def binary_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = torch.round(preds)\n",
        "    correct = (rounded_preds == y).float() #convert into float for division \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc\n",
        "\n",
        "def train(train_loader, net, criterion, optimizer, epoch):\n",
        "\n",
        "    tic = time.time()\n",
        "    \n",
        "    # Setting network for training mode.\n",
        "    net.train()\n",
        "\n",
        "    # Lists for losses and metrics.\n",
        "    train_loss = []\n",
        "    \n",
        "    # Iterating over batches.\n",
        "    for i, batch_data in enumerate(train_loader):\n",
        "\n",
        "        # Obtaining images, labels and paths for batch.\n",
        "        text, text_lengths = batch_data.text\n",
        "        labs = batch_data.label\n",
        "\n",
        "        \n",
        "        # TODO: Passos de treinamento\n",
        "        \n",
        "        \n",
        "        \n",
        "        # Updating lists.\n",
        "        train_loss.append(loss.data.item())\n",
        "    \n",
        "    toc = time.time()\n",
        "    \n",
        "    train_loss = np.asarray(train_loss)\n",
        "    \n",
        "    # Printing training epoch loss and metrics.\n",
        "\n",
        "    print('--------------------------------------------------------------------')\n",
        "    print('[epoch %d], [train loss %.4f +/- %.4f], [training time %.2f]' % (\n",
        "        epoch, train_loss.mean(), train_loss.std(), (toc - tic)))\n",
        "    print('--------------------------------------------------------------------')\n",
        "\n",
        "def test(test_loader, net, criterion, epoch):\n",
        "\n",
        "    tic = time.time()\n",
        "    \n",
        "    # Setting network for evaluation mode (not computing gradients).\n",
        "    net.eval()\n",
        "\n",
        "    # Lists for losses and metrics.\n",
        "    test_loss = []\n",
        "    acc_list = []\n",
        "    lab_list = []\n",
        "    \n",
        "    # Iterating over batches.\n",
        "    for i, batch_data in enumerate(test_loader):\n",
        "\n",
        "        # Obtaining images, labels and paths for batch.\n",
        "        text, text_lengths = batch_data.text\n",
        "        labs = batch_data.label\n",
        "\n",
        "        # TODO Forwarding.\n",
        "\n",
        "\n",
        "        # TODO Computing loss.\n",
        "        \n",
        "                \n",
        "        # Updating lists.\n",
        "        test_loss.append(loss.data.item())\n",
        "        acc_list.append(binary_accuracy(outs, labs).detach().cpu().numpy())\n",
        "        lab_list.append(labs.detach().cpu().numpy())\n",
        "    \n",
        "    toc = time.time()\n",
        "    \n",
        "#     Computing accuracy.\n",
        "    acc = np.mean(acc_list)\n",
        "    \n",
        "    test_loss = np.asarray(test_loss)\n",
        "    \n",
        "    # Printing training epoch loss and metrics.\n",
        "   \n",
        "    print('********************************************************************')\n",
        "    print('[epoch %d], [test loss %.4f +/- %.4f], [acc %.4f] [testing time %.2f]' % (\n",
        "        epoch, test_loss.mean(), test_loss.std(), acc, (toc - tic)))\n",
        "    print('********************************************************************')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xv1H9v7PXlbV",
        "colab_type": "code",
        "outputId": "8658fcec-3a4c-47f3-9617-9c298fa1526c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        }
      },
      "source": [
        "# Iterating over epochs.\n",
        "for epoch in range(1, args['epoch_num'] + 1):\n",
        "\n",
        "    # Training function.\n",
        "    train(train_iterator, net, criterion, optimizer, epoch)\n",
        "\n",
        "    # Computing test loss and metrics.\n",
        "    test(test_iterator, net, criterion, epoch)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------\n",
            "[epoch 1], [train loss 0.5294 +/- 0.1680], [training time 75.99]\n",
            "--------------------------------------------------------------------\n",
            "********************************************************************\n",
            "[epoch 1], [test loss 0.4302 +/- 0.3067], [acc 0.8122] [testing time 41.04]\n",
            "********************************************************************\n",
            "--------------------------------------------------------------------\n",
            "[epoch 2], [train loss 0.3385 +/- 0.1803], [training time 76.31]\n",
            "--------------------------------------------------------------------\n",
            "********************************************************************\n",
            "[epoch 2], [test loss 0.3211 +/- 0.2031], [acc 0.8625] [testing time 40.97]\n",
            "********************************************************************\n",
            "--------------------------------------------------------------------\n",
            "[epoch 3], [train loss 0.2782 +/- 0.1706], [training time 76.56]\n",
            "--------------------------------------------------------------------\n",
            "********************************************************************\n",
            "[epoch 3], [test loss 0.3066 +/- 0.2025], [acc 0.8713] [testing time 40.75]\n",
            "********************************************************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-4196ee387bdc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Training function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Computing test loss and metrics.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-57-c5e31c5007be>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, net, criterion, optimizer, epoch)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;31m# Weight update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;31m# Updating lists.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m                     \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nAYLKC35May",
        "colab_type": "code",
        "outputId": "74ceb8b2-c472-4619-a86f-8ced2f7543d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    print(model)\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "\n",
        "            text, text_lengths = batch.text\n",
        "            \n",
        "            predictions = model(text, text_lengths)\n",
        "            \n",
        "            loss = criterion(predictions, batch.label)\n",
        "            \n",
        "            acc = binary_accuracy(predictions, batch.label)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
        "\n",
        "test_loss, test_acc = evaluate(net, test_iterator, criterion)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BiLSTM(\n",
            "  (embedding): Embedding(25002, 100, padding_idx=1)\n",
            "  (dropout): Dropout(p=0.5)\n",
            "  (bilstm): LSTM(100, 64, bidirectional=True)\n",
            "  (linear): Linear(in_features=256, out_features=1, bias=True)\n",
            "  (activation): Sigmoid()\n",
            ")\n",
            "Test Loss: 0.327 | Test Acc: 86.63%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BGKwtm_1D-c",
        "colab_type": "text"
      },
      "source": [
        "## Predizendo entradas do usuário"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDmiD4tqhZQw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en')\n",
        "\n",
        "def predict_sentiment(model, sentence):\n",
        "    model.eval()\n",
        "    tokenized = [str(tok) for tok in nlp.tokenizer(sentence)]\n",
        "    print(tokenized)\n",
        "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
        "    length = [len(indexed)]\n",
        "    print(indexed)\n",
        "    tensor = torch.LongTensor(indexed).to(args['device'])\n",
        "    tensor = tensor.unsqueeze(1)\n",
        "    length_tensor = torch.LongTensor(length)\n",
        "    prediction = model(tensor, length_tensor)\n",
        "    return prediction.item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9jFD5mIhbIf",
        "colab_type": "code",
        "outputId": "2d2bf093-5818-4fe6-f5c0-7b9513387c2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        }
      },
      "source": [
        "pred = predict_sentiment(net, \"Rocks are NOT stones!\")\n",
        "\n",
        "\n",
        "plt.bar(0, 1-pred, color='darkred', label='Negativo')\n",
        "plt.bar(1, pred, color='dodgerblue', label='Positivo')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Rocks', 'are', 'NOT', 'stones', '!']\n",
            "[24616, 32, 910, 13204, 40]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}
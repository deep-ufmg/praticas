{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "M04_AP3 - Convolutional AutoEncoder.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NG-mVsVuE0if",
        "colab_type": "text"
      },
      "source": [
        "# Preâmbulo\n",
        "\n",
        "Imports, funções, downloads e instalação do Pytorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEHmMCjR4PJw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " # Basic imports.\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils import data\n",
        "from torch.backends import cudnn\n",
        "\n",
        "from torchvision import models\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "\n",
        "from skimage import io\n",
        "\n",
        "from sklearn import metrics\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "cudnn.benchmark = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwhRUUlc4j23",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Setting predefined arguments.\n",
        "args = {\n",
        "    'epoch_num': 10,      # Number of epochs.\n",
        "    'n_classes': 10,      # Number of classes.\n",
        "    'lr': 0.001,          # Learning rate.\n",
        "    'weight_decay': 1e-5, # L2 penalty.\n",
        "    'num_workers': 3,     # Number of workers on data loader.\n",
        "    'batch_size': 100,    # Mini-batch size.\n",
        "    'print_freq': 1, #1,      # Printing frequency.\n",
        "}\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    args['device'] = torch.device('cuda')\n",
        "else:\n",
        "    args['device'] = torch.device('cpu')\n",
        "\n",
        "print(args['device'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20kc9tHQ59ba",
        "colab_type": "text"
      },
      "source": [
        "# Carregando o  MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vi3Zh8fQ4X_3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Root directory for the dataset (to be downloaded).\n",
        "root = './'\n",
        "\n",
        "# Transformations over the dataset.\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# Setting datasets and dataloaders.\n",
        "train_set = datasets.MNIST(root,\n",
        "                           train=True,\n",
        "                           download=True,\n",
        "                           transform=data_transforms)\n",
        "test_set = datasets.MNIST(root,\n",
        "                          train=False,\n",
        "                          download=False,\n",
        "                          transform=data_transforms)\n",
        "\n",
        "# Setting dataloaders.\n",
        "train_loader = DataLoader(train_set,\n",
        "                          args['batch_size'],\n",
        "                          num_workers=args['num_workers'],\n",
        "                          shuffle=True)\n",
        "test_loader = DataLoader(test_set,\n",
        "                         args['batch_size'],\n",
        "                         num_workers=args['num_workers'],\n",
        "                         shuffle=False)\n",
        "\n",
        "# Printing training and testing dataset sizes.\n",
        "print('Size of training set: ' + str(len(train_set)) + ' samples')\n",
        "print('Size of test set: ' + str(len(test_set)) + ' samples')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drOsx-32Ifo1",
        "colab_type": "text"
      },
      "source": [
        "# AutoEncoder Convolucional\n",
        "\n",
        "\n",
        "\n",
        "![Convolutional AE](https://www.dropbox.com/s/mjiofz102bt4n5d/Conv_AE.png?dl=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCkkEt7_YLdo",
        "colab_type": "text"
      },
      "source": [
        "# Atividade Prática: AutoEncoder Convolucional\n",
        "\n",
        "Como mencionado previamente, um AE é uma arquitetura **Encoder-Decoder** com camadas de dimensionalidade simétrica. Vamos definir um AE Convolucional:\n",
        "\n",
        "1.   Crie um Encoder composto por três blocos convolucionais (conv2d + ativação + maxpooling2d) que reduza gradativamente a dimensionalidade inicial dos dados ($28 \\times 28$) para apenas $7 \\times 7$ de resolução espacial no bottleneck. As convoluções devem ser pensadas para manter a dimensão dos dados, de forma que os feature maps só percam resolução espacial por meio do maxpooling2d com kernel size = 2 e stride = 2. A cada conv2d dobre o número de feature maps;\n",
        "2.   Crie um Decoder com dois blocos de convolução transposta(conv2d + ativação + convtranspose2d) que recupere a resolução espacial dos dados. O último bloco do Decoder deve conter apenas uma conv2d seguida de ativação. A cada conv2d, divida o número de feature maps por 2. Visando preservar a simetria da arquitetura, ache uma combinação de parâmetros de forma que Convolução Transposta duplique a resolução espacial dos feature maps de entrada;\n",
        "3.   Implemente o *forward()* passando os dados pelo Encoder e subsequentemente pelo Decoder;\n",
        "4.   Defina a loss function (uma loss de regressão) e o otimizador;\n",
        "5.   Complete as funções *train()* e *test()*.\n",
        "\n",
        "PS. 1: as ativações de todas as camadas convolucionais devem ser ReLU, menos a última camada que deve ter como ativação uma função sigmóide.\n",
        "\n",
        "PS. 2: usar kernel $3 \\times 3$ e stride = 2 nas Convoluções Transpostas e a equação presente na [definição da função](https://pytorch.org/docs/stable/nn.html#convtranspose2d) para resolver os outros parâmetros e duplicar a resolução espacial."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e27D-vk8lFgJ",
        "colab_type": "text"
      },
      "source": [
        "# Definindo a arquitetura"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Y7IHYWg2NBQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# AutoEncoder implementation.\n",
        "class ConvAutoEncoder(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "\n",
        "        super(ConvAutoEncoder, self).__init__()\n",
        "        \n",
        "        # TO DO: define encoder.\n",
        "        self.encoder = # ...\n",
        "        \n",
        "        # TO DO: define decoder.\n",
        "        self.decoder = # ...\n",
        "        \n",
        "        self.initialize_weights()\n",
        "    \n",
        "    # Function for randomly initializing weights.\n",
        "    def initialize_weights(self):\n",
        "        \n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, 0, 0.01)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "                \n",
        "    def forward(self, x):\n",
        "        \n",
        "        # TO DO: implement forward.\n",
        "        # ...\n",
        "\n",
        "# Instantiating architecture.\n",
        "net = ConvAutoEncoder().to(args['device'])\n",
        "\n",
        "# Printing architecture.\n",
        "print(net)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nS2l_pqAI0F2",
        "colab_type": "text"
      },
      "source": [
        "# Definindo o otimizador\n",
        "\n",
        "O Pytorch possui vários otimizadores prontos no subpacote [optim](https://pytorch.org/docs/stable/optim.html), desde o SGD básico a otimizadores mais complexos e com taxas de aprendizado por parâmetro como o Adagrad, RMSProp e Adam."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_-RN1wH-4bB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TO DO: defining optimizer.\n",
        "optimizer = # ..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVhOWUkWKU4f",
        "colab_type": "text"
      },
      "source": [
        "# Definindo a loss\n",
        "\n",
        "A loss de um AE tradicional pode ser vista como uma loss de regressão, como o MSE ou a Loss L1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NX_bmN3__LIK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TO DO: defining regression loss.\n",
        "criterion = # ..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXhZakGZK_kU",
        "colab_type": "text"
      },
      "source": [
        "# Criando funções para Treino e Teste"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCU5Gx9D_6xW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training procedure.\n",
        "def train(train_loader, net, criterion, optimizer, epoch):\n",
        "\n",
        "    tic = time.time()\n",
        "    \n",
        "    # Setting network for training mode.\n",
        "    net.train()\n",
        "\n",
        "    # Lists for losses and metrics.\n",
        "    train_loss = []\n",
        "    \n",
        "    # Iterating over batches.\n",
        "    for i, batch_data in enumerate(train_loader):\n",
        "\n",
        "        # Obtaining images and labels for batch.\n",
        "        inps, labs = batch_data\n",
        "        \n",
        "        # TO DO: Casting to cuda variables.\n",
        "        inps = # ...\n",
        "        \n",
        "        # TO DO: Clearing the gradients of optimizer.\n",
        "        # ...\n",
        "\n",
        "        # TO DO: Forwarding.\n",
        "        outs, cods = # ...\n",
        "\n",
        "        # TO DO: Computing loss.\n",
        "        loss = # ...\n",
        "\n",
        "        # TO DO: Computing backpropagation.\n",
        "        # ...\n",
        "        \n",
        "        # TO DO: Taking step in optimizer.\n",
        "        # ...\n",
        "        \n",
        "        # Updating lists.\n",
        "        train_loss.append(loss.data.item())\n",
        "    \n",
        "    toc = time.time()\n",
        "    \n",
        "    train_loss = np.asarray(train_loss)\n",
        "    \n",
        "    # Printing training epoch loss and metrics.\n",
        "    print('-------------------------------------------------------------------')\n",
        "    print('[epoch %d], [train loss %.4f +/- %.4f], [training time %.2f]' % (\n",
        "        epoch, train_loss.mean(), train_loss.std(), (toc - tic)))\n",
        "    print('-------------------------------------------------------------------')\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eD2mQJjjkSgF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Testing procedure.\n",
        "def test(test_loader, net, criterion, epoch):\n",
        "\n",
        "    tic = time.time()\n",
        "    \n",
        "    # Setting network for evaluation mode.\n",
        "    net.eval()\n",
        "\n",
        "    # Lists for losses and metrics.\n",
        "    test_loss = []\n",
        "    \n",
        "    # Iterating over batches.\n",
        "    for i, batch_data in enumerate(test_loader):\n",
        "\n",
        "        # Obtaining images and labels for batch.\n",
        "        inps, labs = batch_data\n",
        "\n",
        "        # Casting to cuda variables.\n",
        "        inps = # ...\n",
        "\n",
        "        # Forwarding.\n",
        "        outs, cods = # ...\n",
        "\n",
        "        # Computing loss.\n",
        "        loss = # ...\n",
        "        \n",
        "        # Updating lists.\n",
        "        test_loss.append(loss.data.item())\n",
        "        \n",
        "        # Plotting.\n",
        "        if i == 0 and epoch % args['print_freq'] == 0:\n",
        "            \n",
        "            fig, ax = plt.subplots(10, 8, figsize=(16, 20))\n",
        "        \n",
        "        if i < 8 and epoch % args['print_freq'] == 0:\n",
        "            \n",
        "            ax[0, i].imshow(inps[0, 0].detach().cpu().numpy())\n",
        "            ax[0, i].set_yticks([])\n",
        "            ax[0, i].set_xticks([])\n",
        "            ax[0, i].set_title('Image ' + str(i + 1))\n",
        "            \n",
        "            ax[1, i].imshow(outs[0, 0].detach().cpu().numpy())\n",
        "            ax[1, i].set_yticks([])\n",
        "            ax[1, i].set_xticks([])\n",
        "            ax[1, i].set_title('Reconstructed ' + str(i + 1))\n",
        "            \n",
        "            \n",
        "            for c in range(cods.size(1)):\n",
        "                \n",
        "                ax[2 + c, i].imshow(cods[0, c].detach().cpu().numpy())\n",
        "                ax[2 + c, i].set_yticks([])\n",
        "                ax[2 + c, i].set_xticks([])\n",
        "                ax[2 + c, i].set_title('Bottleneck[' + str(c) + '] ' + str(i + 1))\n",
        "            \n",
        "        if i == 8 and epoch % args['print_freq'] == 0:\n",
        "            \n",
        "            plt.show()\n",
        "    \n",
        "    toc = time.time()\n",
        "    \n",
        "    test_loss = np.asarray(test_loss)\n",
        "    \n",
        "    # Printing training epoch loss and metrics.\n",
        "    print('-------------------------------------------------------------------')\n",
        "    print('[epoch %d], [test loss %.4f +/- %.4f], [testing time %.2f]' % (\n",
        "        epoch, test_loss.mean(), test_loss.std(), (toc - tic)))\n",
        "    print('-------------------------------------------------------------------')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ijo07bsTMFMs",
        "colab_type": "text"
      },
      "source": [
        "# Iterando sobre epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RU2aYIob_zTu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Iterating over epochs.\n",
        "for epoch in range(1, args['epoch_num'] + 1):\n",
        "\n",
        "    # Training function.\n",
        "    train(train_loader, net, criterion, optimizer, epoch)\n",
        "\n",
        "    # Computing test loss and metrics.\n",
        "    test(test_loader, net, criterion, epoch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KaCJ0gjaui1Z",
        "colab_type": "text"
      },
      "source": [
        "# Usando a representação de bottleneck como Deep Features\n",
        "\n",
        "A camada de bottleneck de um AE Linear ou Convolucional pode ser linearizada e utilizada como **Deep Features** que podem servir de entrada para um algoritmo que vá realizar uma tarefa qualquer de Machine Learning (i.e. clusterização, regressão, classificação, etc). Dessa forma, o Encoder da rede passa a ser um extrator de **Deep Features** não-supervisionado.\n",
        "\n",
        "![Conv AE Extractor](https://www.dropbox.com/s/11s5a5ynlu4g4wp/Conv_AE_Extractor.png?dl=1)\n",
        "\n",
        "Nota-se que o Encoder foi otimizado para minimizar a reconstrução dos dados -- e não a classificação dos dígitos, no caso do MNIST -- conseguindo resultados de classificação que não podem ser equiparados aos modelos treinados de forma supervisionada end-to-end, porém ainda melhores que a maioria dos **Handcrafted Features**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xo0ifAgv_q3g",
        "colab_type": "text"
      },
      "source": [
        "# Atividade Prática: Usando o Encoder como Extrator\n",
        "\n",
        "Nessa atividade usaremos o Encoder do nosso AE Convolucional pré-treinado como extrator de features, passando os rótulos dos números como labels para o [Random Forest do sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html). Para isso, implemente os seguintes passos:\n",
        "\n",
        "1.   Leia o conjunto de treino usando o *train_loader* pré-definido, faça o *forward* de cada batch sobre o encoder apenas, consiga a representação intermediária, linearize e salve amostra por amostra na lista *train_samples*. Os rótulos das imagens devem ser salvos (novamente amostra por amostra) na lista *train_labels*. Ambos features e rótulos devem ser transformados para arrays do numpy antes de serem salvos nas listas. Dica: usar função [*append()*](https://www.programiz.com/python-programming/methods/list/append) das listas do python;\n",
        "2.   Faça o mesmo do passo 1., mas para o conjunto de teste e salvando nas listas *test_samples* e *test_labels*;\n",
        "3.   Lembre-se de transformar as listas de features e labels para numpy usando a função [*np.asarray()*](https://docs.scipy.org/doc/numpy/reference/generated/numpy.asarray.html);\n",
        "4.   Instancie um Random Forest do sklearn de acordo com o link a cima;\n",
        "5.   Treine o Random Forest com os features e labels do conjunto de treino do MNIST. Dica: método [*.fit(X_train, Y_train)*](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier.fit);\n",
        "6.   Teste a classificação nos features e labels do conjunto de testes do MNIST. Dica: método [*.predict(X_teste)*](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier.predict);\n",
        "7.   Calcule a [acurácia](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html) do modelo para o conjunto de testes;\n",
        "8.   Realize o mesmo procedimento para o AE Linear e compare os resultados com o AE Convolucional."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PSHxnTYujZB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import svm\n",
        "from sklearn import ensemble\n",
        "from sklearn import metrics\n",
        "\n",
        "# Evaluating procedure for digit classification.\n",
        "def evaluate(train_loader, test_loader, net):\n",
        "    \n",
        "    tic = time.time()\n",
        "    \n",
        "    # Setting network for evaluation mode.\n",
        "    net.eval()\n",
        "\n",
        "    # Lists for features and labels.\n",
        "    train_samples = []\n",
        "    train_labels = []\n",
        "    \n",
        "    test_samples = []\n",
        "    test_labels = []\n",
        "    \n",
        "    ############################################################################\n",
        "    # TO DO: Iterating over training batches. ##################################\n",
        "    ############################################################################\n",
        "    for i, batch_data in enumerate(train_loader):\n",
        "\n",
        "        # TO DO: Obtaining images and labels for batch.\n",
        "        inps, labs = batch_data\n",
        "\n",
        "        # TO DO: Casting to cuda variables and reshaping.\n",
        "        inps = # ...\n",
        "\n",
        "        # TO DO: Forwarding.\n",
        "        outs, cods = # ...\n",
        "        \n",
        "        # Iterating over images in batch.\n",
        "        for b in range(inps.size(0)):\n",
        "            \n",
        "            # TO DO: Using encodings cods[b] and cast them to cpu and numpy.\n",
        "            features = # ...\n",
        "            \n",
        "            # TO DO: Using labels labs[b].\n",
        "            label = # ...\n",
        "            \n",
        "            # TO DO: Append lists with features and label of the current sample.\n",
        "            # ...\n",
        "\n",
        "    ############################################################################\n",
        "    # TO DO: Iterating over test batches. ######################################\n",
        "    ############################################################################\n",
        "    for i, batch_data in enumerate(test_loader):\n",
        "\n",
        "        # TO DO: Obtaining images and labels for batch.\n",
        "        inps, labs = batch_data\n",
        "\n",
        "        # TO DO: Casting to cuda variables and reshaping.\n",
        "        inps = # ...\n",
        "\n",
        "        # TO DO: Forwarding.\n",
        "        outs, cods = # ...\n",
        "        \n",
        "        # Iterating over images in batch.\n",
        "        for b in range(inps.size(0)):\n",
        "            \n",
        "            # TO DO: Using encodings cods[b] and cast them to cpu and numpy.\n",
        "            features = # ...\n",
        "            \n",
        "            # TO DO: Using labels labs[b].\n",
        "            label = # ...\n",
        "            \n",
        "            # TO DO: Append lists with features and label of the current sample.\n",
        "            # ...\n",
        "    \n",
        "    # TO DO: Transforming lists to numpy arrays.\n",
        "    train_samples = # ...\n",
        "    train_labels = # ...\n",
        "    \n",
        "    test_samples = # ...\n",
        "    test_labels = # ...\n",
        "    \n",
        "    \n",
        "    # TO DO: Instantiating Random Forest.\n",
        "    clf_rf = # ...\n",
        "    \n",
        "    # TO DO: Fitting training data.\n",
        "    # ...\n",
        "    \n",
        "    # TO DO: Predicting test data.\n",
        "    # ...\n",
        "    \n",
        "    # TO DO: Computing accuracy.\n",
        "    acc_rf = # ...\n",
        "    \n",
        "    toc = time.time()\n",
        "    \n",
        "    # Using the features to perform classification on a supervised setting.\n",
        "    print('-------------------------------------------------------------------')\n",
        "    print('[rf accuracy %.4f], [time %.2f]' % (\n",
        "        acc_rf, (toc - tic)))\n",
        "    print('-------------------------------------------------------------------')\n",
        "    \n",
        "# Calling evaluation function.\n",
        "evaluate(train_loader, test_loader, net)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
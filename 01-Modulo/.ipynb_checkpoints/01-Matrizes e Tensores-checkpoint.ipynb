{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aprendizado Profundo - UFMG\n",
    "\n",
    "## Preâmbulo\n",
    "\n",
    "O código abaixo consiste dos imports comuns. Além do mais, configuramos as imagens para ficar de um tamanho aceitável e criamos algumas funções auxiliares. No geral, você pode ignorar a próxima célula.\n",
    "\n",
    "O curso nosso vai fazer uso extensivo de [mxnet](http://mxnet.apache.org). Importamos o mesmo com as seguintes linhas:\n",
    "\n",
    "```python\n",
    "import mxnet as mx\n",
    "import mxnet.ndarray as nd```\n",
    "\n",
    "Para instalar no collab, descomente e execute a célula abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install mxnet-cu100==1.4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf8\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import mxnet as mx\n",
    "import mxnet.ndarray as nd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "plt.rcParams['figure.figsize']  = (18, 10)\n",
    "plt.rcParams['axes.labelsize']  = 20\n",
    "plt.rcParams['axes.titlesize']  = 20\n",
    "plt.rcParams['legend.fontsize'] = 20\n",
    "plt.rcParams['xtick.labelsize'] = 20\n",
    "plt.rcParams['ytick.labelsize'] = 20\n",
    "plt.rcParams['lines.linewidth'] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ion()\n",
    "\n",
    "plt.style.use('seaborn-colorblind')\n",
    "plt.rcParams['figure.figsize']  = (12, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para testar o resultado dos seus algoritmos vamos usar o módulo testing do numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.testing import assert_equal\n",
    "from numpy.testing import assert_almost_equal\n",
    "from numpy.testing import assert_array_almost_equal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aula 01 - Programação Diferenciável e Tensores\n",
    "\n",
    "Quando pensamos no lado prático do aprendizado profundo, um aspecto chave que ajuda na implementação de novos algoritmos é a chamada programação diferenciável. Na próxima aula vamos voltar na mesma. No momento, o importante é salientar que a programação diferenciável faz uso extensivo de Tensores. Um [Tensor](http://en.wikipedia.org/wiki/Tensor) é uma generalização de matrizes para mais dimensões. Quando falamos de tensores, temos três casos especiais e um genérico que engloba os outros três:\n",
    "\n",
    "1. **Escalar:** Um tensor de zero dimensões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Vetor:** Um tensor de uma dimensão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([1, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Matrizes:** Um tensor de duas dimensões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([[1, 2], [2, 2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Tensores**. Caso geral, representam n-dimensões. Na figura temos um tensor 3x3x3.\n",
    "\n",
    "![](./figs/tensor.png)\n",
    "\n",
    "No exemplo abaixo, temos um tensor 3x2x2. Note ao selecionar elementos da primeira dimensão ficamos com matrizes 2x2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.randn(3, 2, 2) # Gera números aleatórios de uma normal\n",
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexando\n",
    "\n",
    "Sendo X uma matriz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1, 2], [2, 2]])\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`X[l]` pega uma linha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`X[:, c]` pega uma coluna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`X[um_vetor]` pega as linhas do vetor. `X[:, um_vetor]` pega as colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1, 2, 3], [2, 2, 2]])\n",
    "X[:, [1, 2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`X[vetor_booleano]` Retorna as linhas (ou colunas quando `X[:, vetor_booleano]`) onde o vetor é true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[[False, True]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shape, Reshape e Ravel\n",
    "\n",
    "Todo vetor, matriz e tensor pode ser redimensionado. Observe como no tensor abaixo temos `3x2x2=12` elementos. Podemos redimensionar os mesmos para outros arrays de tamanho 12."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.randn(3, 2, 2)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como matriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.reshape((2, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outra Matriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.reshape((6, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.reshape((6, 2, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As operações flatten e ravel organizam os elementos como um vetor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arrays Assíncronos\n",
    "\n",
    "Em todos os exemplos abaixo vamos fazer uso pesado de matrizes e tensores. A biblioteca mxnet, contém uma biblioteca de tensores que é **quase igual** a biblioteca numpy. Observe como usando:\n",
    "\n",
    "```python\n",
    "import mxnet.ndarray as nd\n",
    "```\n",
    "\n",
    "Temos as mesmas primitivas de um vetor numpy. Portanto vamos fazer uso do módulo ND em boa parte das nossas tarefas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([[1, 2], [2, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nd.array([[1, 2], [2, 1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma diferença, é que o mxnet executa operações de forma assíncrona. Isto é uma característica comum de diversos arcabouços de aprendizado profundo. Então, diferente de numpy onde cada resultado já está pronto logo ao realizar a operação:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "tic = time.time()\n",
    "X = np.random.normal(size=(10000, 1000))\n",
    "Y = np.random.normal(size=(1000, 20000))\n",
    "R = np.dot(X, Y)  # produto de matrizes\n",
    "time.time() - tic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em mxnet só temos a resposta ao ler o valor de retorno. A multiplicação `R = X @ Y` não é realizada ao executar a linha. Observe como o código termina muito muito rápido!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "X = nd.random.normal(shape=(10000, 1000)) #shape ao invés de size, api um pouco inconsistente\n",
    "Y = nd.random.normal(shape=(1000, 20000))\n",
    "R = nd.dot(X, Y)\n",
    "# até aqui não temos garantias que R foi computada\n",
    "time.time() - tic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao realizar wait_to_read, esperamos o resutado ficar pronto. O mesmo ocorre se acessar um valor de R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "X = nd.random.normal(shape=(10000, 1000)) #shape ao invés de size, api um pouco inconsistente\n",
    "Y = nd.random.normal(shape=(1000, 20000))\n",
    "R = nd.dot(X, Y)\n",
    "R.wait_to_read()\n",
    "time.time() - tic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conjunto de Problemas 1: Vetorização"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seu objetivo é medir a velocidade das operações de álgebra linear para diferentes níveis de vetorização. Você precisa usar `wait_to_read ()` na saída para assegurar que o resultado seja computado completamente.\n",
    "\n",
    "1. Construa duas matrizes $ A $ e $ B $ com entradas aleatórias Gaussianas de tamanho $ 128 \\times 256 $. Use o módulo time para mensurar o tempo da operação. Lembre-se de chamar wait_to_read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descomente e complete\n",
    "# A = nd...\n",
    "# B = nd..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testes, não apague as linhas!!\n",
    "assert_equal((128, 256), A.shape)\n",
    "assert_equal((128, 256), B.shape)\n",
    "\n",
    "# A chamada asnumpy converte os vetores em vetores numpy. Útil para testes!\n",
    "Anp = A.asnumpy()\n",
    "Bnp = A.asnumpy()\n",
    "\n",
    "# testando média e desvio padrão\n",
    "assert_almost_equal(Anp.mean(), 0, decimal=2)\n",
    "assert_almost_equal(Anp.std(ddof=1), 1, decimal=2)\n",
    "\n",
    "assert_almost_equal(Bnp.mean(), 0, decimal=2)\n",
    "assert_almost_equal(Bnp.std(ddof=1), 1, decimal=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Calcule $ C = AB^t $, tratando $ A $ como uma matriz, mas computando o resultado para cada coluna de $ B $. Isto é, use um laço `for`! Pare realizar este código, é importante entender o conceito de broadcasting. Para transpor uma matriz use `X.T`.\n",
    "\n",
    "Em código numpy e mxnet, a operação de broadcasting replica linhas e colunas de tensores para realizar operações. Para entender melhor, leia o [documento](https://docs.scipy.org/doc/numpy/user/basics.broadcasting.html). A figura abaixo exemplifica broadcasting. No geral, as dimensões de arrays casam, as operações são realizadas (primeira linha da figura). Mesmo quando as dimensões não casem, se a última dimensão for compatível é feito a replicação (broadcasting), ver a segunda linha da figura. Por fim, mesmo quando as dimensões não casam mas uma delas é 1 (4x1 + 1x3 na linha 3), é feito broadcasting.\n",
    "\n",
    "Para fazer o código em uma linha apenas, você vai focar no caso da linha 2 da figura. Multiplique uma linha de A por B. Depois disso, use `.sum(axis=...)`.\n",
    "\n",
    "![](./figs/broadcasting.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descomente e complete\n",
    "C = nd.zeros(shape=(128, 128))\n",
    "for linha in range(B.shape[0]):\n",
    "    C[linha] = # ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testes, não apague as linhas!!\n",
    "Cteste = nd.dot(A, B.T).asnumpy()  # faz a leitura, realiza operação\n",
    "assert_array_almost_equal(Cteste, C.asnumpy(), decimal=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Calcule $ C = AB^t $ usando operações matriciais. Ou seja, sem usar nenhum laço. Ao mensurar o tempo, ficou mais rápido?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testes, não apague as linhas!!\n",
    "Cteste = nd.dot(A, B.T).asnumpy()  # faz a leitura, realiza operação\n",
    "assert_array_almost_equal(Cteste, C.asnumpy(), decimal=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conjunto de Problemas 2: Computação eficiente de memória\n",
    "\n",
    "Crie duas matrizes aleatórias de tamanho $4096 \\times 4096$. Chame as mesmas de A e B novamente.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = nd.random.normal(shape=(4096, 4096))\n",
    "B = nd.random.normal(shape=(4096, 4096))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Queremos calcular $ C \\leftarrow A \\cdot B + C $, onde $ A, B $ e $ C $ são todas matrizes. Implemente isso da maneira mais eficiente em termos de memória!\n",
    "\n",
    "4. Não aloque nova memória para o novo valor de $ C $. Não aloque nova memória para resultados intermediários, se possível. Leia a seção de Saving Memory do [d2l.ai](http://d2l.ai/chapter_crashcourse/ndarray.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descomente e complete\n",
    "C = nd.zeros(A.shape)\n",
    "C[:] = # ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testes não apague!\n",
    "Cteste = (nd.dot(A, B)).asnumpy()  # faz a leitura, realiza operação\n",
    "assert_array_almost_equal(Cteste, C.asnumpy(), decimal=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Crie uma função que recebe (A, B e C). A mesma deve atualizar C sem alocar memória nova. Além do mais, a função recebe um número de iterações para atualizar C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_c(C, A, B, niter=2):\n",
    "    # implemente\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testes não apague!\n",
    "Ct = nd.zeros(A.shape)\n",
    "Cteste = (Ct + nd.dot(A, B))\n",
    "Cteste = (Cteste + nd.dot(A, B)).asnumpy()\n",
    "\n",
    "C = nd.zeros(A.shape)\n",
    "update_c(C, A, B, 2)\n",
    "assert_array_almost_equal(Cteste, C.asnumpy(), decimal=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conjunto de Problemas 3: Programação Diferenciável\n",
    "\n",
    "Agora vamos aprender um dos pontos chaves de fazer uso de bibliotecas como mxnet/tensorflow/etc, a programação diferenciável. Diferente do exercício que vocês fizeram na mão, usando a biblioteca conseguimos derivar de forma automágica. Portanto, observe como o código abaixo deriva a função seno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-10, 10, 1000)\n",
    "x_nd = nd.array(x)\n",
    "x_nd.attach_grad()\n",
    "with mx.autograd.record(): # liga o modo treino, vamos derivar e otimizar coisas.\n",
    "    y = nd.sin(x_nd)\n",
    "y.backward()\n",
    "\n",
    "plt.plot(x_nd.asnumpy(), y.asnumpy(), label='sin(x)')\n",
    "plt.plot(x_nd.asnumpy(), x_nd.grad.asnumpy(), label='sin\\'(x)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O resultado é a mesma curva da função cosseno! Para entender melhor o autograd, leia a seção respectiva do [d2l.ai](http://d2l.ai/chapter_crashcourse/autograd.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_nd.asnumpy(), x_nd.grad.asnumpy(), label='sin\\'(x)')\n",
    "plt.plot(x_nd.asnumpy(), nd.cos(x_nd).asnumpy(), label='cos(x)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Derive a função logística usando mxnet.\n",
    "\n",
    "$$f(x) = \\frac{1}{1 + e^{-x}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete\n",
    "x = np.linspace(-10, 10, 1000) # Não mude o valor de x!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testes, não apague!!!\n",
    "y_test = 1.0/(1 + np.exp(-x))\n",
    "derivada_teste = y_test * (1 - y_test)\n",
    "assert_array_almost_equal(derivada_teste, x_nd.grad.asnumpy(), decimal=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A operação *dettach* permite quebrar a computação em várias partes. Em particular, isto é útil para aplicar a regra da cadeia. Suponha que $u = f(x)$ e $z = g(u)$, pela regra da cadeia, temos $\\frac{dz}{dx}$ = $\\frac{dz}{du}\\frac{du}{dx}$. Para calcular $\\frac{dz}{du}$, podemos primeiro separar $u$ da computação e, em seguida, chamar `z.backward()` para calcular o primeiro termo.\n",
    "\n",
    "Observe no caso abaixo como derivamos $u = x^2$. A resposta deve ser $2x$ para cada termo `[0, 1, 2, 3]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = nd.arange(4)\n",
    "x.attach_grad()\n",
    "with mx.autograd.record():\n",
    "    u = x * x\n",
    "u.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos fazer $z = u^3$ e computar as derivadas intermediarias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = nd.arange(4)\n",
    "x.attach_grad()\n",
    "with mx.autograd.record():\n",
    "    u = x * x\n",
    "    v = u.detach()  # u still keeps the computation graph\n",
    "    v.attach_grad()\n",
    "    z = v * v * v\n",
    "u.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acima temos a derivada de x ao quadrado. Abaixo temos a derivada de g(x^2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.backward()\n",
    "v.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Agora, sendo $f(x) = 1 + x^2$ e $g(x) = 1 + 7 x^9$. Vamos aplicar a regra da cadeia em mxnet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete\n",
    "x = nd.arange(4)\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# teste para x\n",
    "assert_array_almost_equal([0, 2, 4, 6], x.grad.asnumpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# teste para gx\n",
    "expected = np.array([6.3000000e+01, 1.6128000e+04, 2.4609376e+07, 6.300000256000e+09])\n",
    "assert_array_almost_equal(expected, v.grad.asnumpy(), 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conjunto de Problemas 4: Perceptron from Scratch\n",
    "\n",
    "Por fim, vamos implementar o algoritmo de Perceptron usando mxnet. Inicialmente, vamos gerar dois blobs linearmente separáveis. Com um seed bem setado, claramente teremos duas classes abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "state = np.random.seed(20190187)\n",
    "\n",
    "X, y = datasets.make_blobs(n_samples=200, n_features=2, centers=2)\n",
    "plt.scatter(X[:, 0], X[:, 1], s=80, edgecolors='k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Converta X e y para array mxnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = nd.array(X)\n",
    "y = nd.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para realizar as nossas previsões, precisamos aplicar a seguinte função:\n",
    "\n",
    "$$\\hat{y}_i = \\frac{1}{1 + e^{-(1 + \\theta_1 x_{i1} + \\theta_1 x_{i2}) + \\cdots}}$$\n",
    "\n",
    "Aqui $\\hat{y}_i$ é a previsão de um único elemento. Podemos gerar uma matriz de previsões usando a forma matricial abaixo.\n",
    "\n",
    "![](./figs/linear.png)\n",
    "\n",
    "9. Sabendo que precisamos de uma coluna de valores 1 na nossa entrada $\\mathbf{X}$, implemente uma função chamada `add_intercept` que adicionar uma nova coluna em X. A mesma deve retornar uma cópia! Não altere a matriz original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_intercept(X):\n",
    "    # implemente\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testes, não apague!\n",
    "X_teste = nd.zeros(shape=(4, 4))\n",
    "X_novo_teste = add_intercept(X_teste)\n",
    "X_novo_teste = X_novo_teste.asnumpy()\n",
    "assert_equal(X_teste.shape[0], X_novo_teste.shape[0])\n",
    "assert_equal(X_teste.shape[1] + 1, X_novo_teste.shape[1])\n",
    "assert_array_almost_equal(np.ones(X_novo_teste.shape[0]), X_novo_teste[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Implemente uma função activation que faz uso da sigmoid. A mesma deve retornar um vetor de previsões para um X de entrada. Como regra, assuma que quando a ativação tem valor maior do que 0.5 vamos prever a classe 1. Então, sua resposta deve ser um vetoe de 0s e 1s apenas. Não use nenhum laço!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation(X, theta, limiar=0.5):\n",
    "    # implemente\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testes, não apague!\n",
    "X_teste = nd.random.normal(shape=(1000, 20000))\n",
    "theta = nd.random.normal(shape=(20000))\n",
    "y_hat_teste = activation(X_teste, theta)\n",
    "assert_equal(True, (y_hat_teste >= 0).asnumpy().all())\n",
    "assert_equal(True, (y_hat_teste <= 1).asnumpy().all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Por fim, implemente agora o algoritmo do perceptron. O mesmo deve retornar um vetor de parâmetros theta. Execute o mesmo em X (com ou sem intercepto, no nosso exemplo simples não importa muito)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = np.random.seed(20190187)\n",
    "X, y = datasets.make_blobs(n_samples=200, n_features=2, centers=2)\n",
    "plt.scatter(X[:, 0], X[:, 1], s=80, edgecolors='k')\n",
    "\n",
    "X = nd.array(X)\n",
    "y = nd.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron(X, y, rate=0.001):\n",
    "    Xn = add_intercept(X)\n",
    "    # implemente\n",
    "theta = perceptron(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seu perceptron deve prever perfeitamente as classes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xn = add_intercept(X)\n",
    "y_p = activation(Xn, theta) > 0.5\n",
    "print(y == y_p) # deve ser tudo 1!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
